<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis的数据淘汰]]></title>
    <url>%2F2017%2F06%2F03%2FRedis%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B7%98%E6%B1%B0%2F</url>
    <content type="text"><![CDATA[前言在Redis中，允许用户设置最大使用内存大小server.maxmemory，在内存限定的情况下是很有用的。例如：在一台8G服务器上部署了4个redis服务点，每一个服务点分配 2G的内存大小，减少内存紧张的情况，由此获取更为稳健的服务。 当Redis被当做缓存来使用，当你新增数据时，让它自动地回收旧数据是件很方便的事情。LRU是Redis唯一支持的回收方法。Redis的maxmemory指令用于将可用内存限制成一个固定大小，还包括了Redis使用的LRU(Least Recently Used)算法，这个实际上只是近似的LRU。 Redis中当内存超过限制时，按照配置的策略，淘汰掉相应的键值对数据，使得内存可以继续留有足够的空间保存新的数据。 redis.conf文件中有对该机制的一份很好的解释:123456789101112131415161718192021222324# Don't use more memory than the specified amount of bytes.# When the memory limit is reached Redis will try to remove keys# according to the eviction policy selected (see maxmemory-policy).## If Redis can't remove keys according to the policy, or if the policy is# set to 'noeviction', Redis will start to reply with errors to commands# that would use more memory, like SET, LPUSH, and so on, and will continue# to reply to read-only commands like GET.## This option is usually useful when using Redis as an LRU cache, or to set# a hard memory limit for an instance (using the 'noeviction' policy).## WARNING: If you have slaves attached to an instance with maxmemory on,# the size of the output buffers needed to feed the slaves are subtracted# from the used memory count, so that network problems / resyncs will# not trigger a loop where keys are evicted, and in turn the output# buffer of slaves is full with DELs of keys evicted triggering the deletion# of more keys, and so forth until the database is completely emptied.## In short... if you have slaves attached it is suggested that you set a lower# limit for maxmemory so that there is some free RAM on the system for slave# output buffers (but this is not needed if the policy is 'noeviction').## maxmemory &lt;bytes&gt; 回收策略Redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。maxmemory限制达到的时候Redis会使用的行为由 Redis的maxmemory-policy配置指令来进行配置。Redis提供6种数据淘汰策略：(1)volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰;(2)volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰;(3)volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰;(4)allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰;(5)allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰;(6)noeviction（驱逐）：禁止驱逐数据; 选择正确的回收策略是非常重要的，取决于应用的访问模式，不过你可以在运行时进行相关的策略调整，并且监控缓存命中率和没命中的次数，通过RedisINFO命令输出以便调优。一般的经验规则:使用allkeys-lru策略：当你希望你的请求符合一个幂定律分布，也就是说，你希望部分的子集元素将比其它其它元素被访问的更多。如果你不确定选择什么，这是个很好的选择。.使用allkeys-random：如果你是循环访问，所有的键被连续的扫描，或者你希望请求分布正常（所有元素被访问的概率都差不多）。使用volatile-ttl：如果你想要通过创建缓存对象时设置TTL值，来决定哪些对象应该被过期。allkeys-lru 和 volatile-random策略对于当你想要单一的实例实现缓存及持久化一些键时很有用。不过一般运行两个实例是解决这个问题的更好方法。为了键设置过期时间也是需要消耗内存的，所以使用allkeys-lru这种策略更加高效，因为没有必要为键取设置过期时间当内存有压力时。 如何工作回收进程如何工作的:1.一个客户端运行了新的命令，添加了新的数据。2.Redis检查内存使用情况，如果大于maxmemory的限制, 则根据设定好的策略进行回收。3.一个新的命令被执行，等等。所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。 数据淘汰机制LRU数据淘汰机制在服务器配置中保存了lru计数器 server.lrulock，会定时（redis 定时程序serverCorn()）更新，server.lrulock 的值是根据server.unixtime计算出来。另外，从struct redisObject中可以发现，每一个redis对象都会设置相应的lru。可以想象的是，每一次访问数据的时候，会更新 redisObject.lru。LRU数据淘汰机制：在数据集中随机挑选几个键值对，取出其中lru最大的键值对淘汰。所以redis并不是保证取得所有数据集中最近最少使用（LRU）的键值对，而只是随机挑选的几个键值对中的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// redisServer 保存了 lru 计数器struct redisServer &#123; ... unsigned lruclock:22; /* Clock incrementing every minute, for LRU */ ...&#125;;// 每一个 redis 对象都保存了 lru#define REDIS_LRU_CLOCK_MAX ((1&lt;&lt;21)-1) /* Max value of obj-&gt;lru */#define REDIS_LRU_CLOCK_RESOLUTION 10 /* LRU clock resolution in seconds */typedef struct redisObject &#123; // 刚刚好 32 bits // 对象的类型，字符串/列表/集合/哈希表 unsigned type:4; // 未使用的两个位 unsigned notused:2; /* Not used */ // 编码的方式，redis 为了节省空间，提供多种方式来保存一个数据 // 譬如：“123456789” 会被存储为整数 123456789 unsigned encoding:4; unsigned lru:22; /* lru time (relative to server.lruclock) */ // 引用数 int refcount; // 数据指针 void *ptr;&#125; robj;// redis 定时执行程序。联想：linux cronint serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) &#123; ...... /* We have just 22 bits per object for LRU information. * So we use an (eventually wrapping) LRU clock with 10 seconds resolution. * 2^22 bits with 10 seconds resolution is more or less 1.5 years. * * Note that even if this will wrap after 1.5 years it's not a problem, * everything will still work but just some object will appear younger * to Redis. But for this to happen a given object should never be touched * for 1.5 years. * * Note that you can change the resolution altering the * REDIS_LRU_CLOCK_RESOLUTION define. */ updateLRUClock(); ......&#125;// 更新服务器的 lru 计数器void updateLRUClock(void) &#123; server.lruclock = (server.unixtime/REDIS_LRU_CLOCK_RESOLUTION) &amp; REDIS_LRU_CLOCK_MAX;&#125; TTL数据淘汰机制Redis数据集数据结构中保存了键值对过期时间的表，即redisDb.expires。和LRU数据淘汰机制类似。TTL数据淘汰机制：从过期时间的表中随机挑选几个键值对，取出其中ttl最大的键值对淘汰。同样，redis并不是保证取得所有过期时间的表中最快过期的键值对，而只是随机挑选的几个键值对中的。 另外，redis每服务客户端执行一个命令的时候，会检测使用的内存是否超额。如果超额，即进行数据淘汰。相关Redis代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207// 执行命令int processCommand(redisClient *c) &#123; ...... // 内存超额 /* Handle the maxmemory directive. * * First we try to free some memory if possible (if there are volatile * keys in the dataset). If there are not the only thing we can do * is returning an error. */ if (server.maxmemory) &#123; int retval = freeMemoryIfNeeded(); if ((c-&gt;cmd-&gt;flags &amp; REDIS_CMD_DENYOOM) &amp;&amp; retval == REDIS_ERR) &#123; flagTransaction(c); addReply(c, shared.oomerr); return REDIS_OK; &#125; &#125; ......&#125;// 如果需要，是否一些内存int freeMemoryIfNeeded(void) &#123; size_t mem_used, mem_tofree, mem_freed; int slaves = listLength(server.slaves); // redis 从机回复空间和 AOF 内存大小不计算入 redis 内存大小 /* Remove the size of slaves output buffers and AOF buffer from the * count of used memory. */ mem_used = zmalloc_used_memory(); // 从机回复空间大小 if (slaves) &#123; listIter li; listNode *ln; listRewind(server.slaves,&amp;li); while((ln = listNext(&amp;li))) &#123; redisClient *slave = listNodeValue(ln); unsigned long obuf_bytes = getClientOutputBufferMemoryUsage(slave); if (obuf_bytes &gt; mem_used) mem_used = 0; else mem_used -= obuf_bytes; &#125; &#125; // server.aof_buf &amp;&amp; server.aof_rewrite_buf_blocks if (server.aof_state != REDIS_AOF_OFF) &#123; mem_used -= sdslen(server.aof_buf); mem_used -= aofRewriteBufferSize(); &#125; // 内存是否超过设置大小 /* Check if we are over the memory limit. */ if (mem_used &lt;= server.maxmemory) return REDIS_OK; // redis 中可以设置内存超额策略 if (server.maxmemory_policy == REDIS_MAXMEMORY_NO_EVICTION) return REDIS_ERR; /* We need to free memory, but policy forbids. */ /* Compute how much memory we need to free. */ mem_tofree = mem_used - server.maxmemory; mem_freed = 0; while (mem_freed &lt; mem_tofree) &#123; int j, k, keys_freed = 0; // 遍历所有数据集 for (j = 0; j &lt; server.dbnum; j++) &#123; long bestval = 0; /* just to prevent warning */ sds bestkey = NULL; struct dictEntry *de; redisDb *db = server.db+j; dict *dict; // 不同的策略，选择的数据集不一样 if (server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_LRU || server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_RANDOM) &#123; dict = server.db[j].dict; &#125; else &#123; dict = server.db[j].expires; &#125; // 数据集为空，继续下一个数据集 if (dictSize(dict) == 0) continue; // 随机淘汰随机策略：随机挑选 /* volatile-random and allkeys-random policy */ if (server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_RANDOM || server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_RANDOM) &#123; de = dictGetRandomKey(dict); bestkey = dictGetKey(de); &#125; // LRU 策略：挑选最近最少使用的数据 /* volatile-lru and allkeys-lru policy */ else if (server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_LRU || server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_LRU) &#123; // server.maxmemory_samples 为随机挑选键值对次数 // 随机挑选 server.maxmemory_samples个键值对，驱逐最近最少使用的数据 for (k = 0; k &lt; server.maxmemory_samples; k++) &#123; sds thiskey; long thisval; robj *o; // 随机挑选键值对 de = dictGetRandomKey(dict); // 获取键 thiskey = dictGetKey(de); /* When policy is volatile-lru we need an additional lookup * to locate the real key, as dict is set to db-&gt;expires. */ if (server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_LRU) de = dictFind(db-&gt;dict, thiskey); o = dictGetVal(de); // 计算数据的空闲时间 thisval = estimateObjectIdleTime(o); // 当前键值空闲时间更长，则记录 /* Higher idle time is better candidate for deletion */ if (bestkey == NULL || thisval &gt; bestval) &#123; bestkey = thiskey; bestval = thisval; &#125; &#125; &#125; // TTL 策略：挑选将要过期的数据 /* volatile-ttl */ else if (server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_TTL) &#123; // server.maxmemory_samples 为随机挑选键值对次数 // 随机挑选 server.maxmemory_samples个键值对，驱逐最快要过期的数据 for (k = 0; k &lt; server.maxmemory_samples; k++) &#123; sds thiskey; long thisval; de = dictGetRandomKey(dict); thiskey = dictGetKey(de); thisval = (long) dictGetVal(de); /* Expire sooner (minor expire unix timestamp) is better * candidate for deletion */ if (bestkey == NULL || thisval &lt; bestval) &#123; bestkey = thiskey; bestval = thisval; &#125; &#125; &#125; // 删除选定的键值对 /* Finally remove the selected key. */ if (bestkey) &#123; long long delta; robj *keyobj = createStringObject(bestkey,sdslen(bestkey)); // 发布数据更新消息，主要是 AOF 持久化和从机 propagateExpire(db,keyobj); // 注意， propagateExpire() 可能会导致内存的分配， propagateExpire() 提前执行就是因为 redis 只计算 dbDelete() 释放的内存大小。倘若同时计算 dbDelete() 释放的内存和 propagateExpire() 分配空间的大小，与此同时假设分配空间大于释放空间，就有可能永远退不出这个循环。 // 下面的代码会同时计算 dbDelete() 释放的内存和 propagateExpire() 分配空间的大小： // propagateExpire(db,keyobj); // delta = (long long) zmalloc_used_memory(); // dbDelete(db,keyobj); // delta -= (long long) zmalloc_used_memory(); // mem_freed += delta; ///////////////////////////////////////// /* We compute the amount of memory freed by dbDelete() alone. * It is possible that actually the memory needed to propagate * the DEL in AOF and replication link is greater than the one * we are freeing removing the key, but we can't account for * that otherwise we would never exit the loop. * * AOF and Output buffer memory will be freed eventually so * we only care about memory used by the key space. */ // 只计算 dbDelete() 释放内存的大小 delta = (long long) zmalloc_used_memory(); dbDelete(db,keyobj); delta -= (long long) zmalloc_used_memory(); mem_freed += delta; server.stat_evictedkeys++; // 将数据的删除通知所有的订阅客户端 notifyKeyspaceEvent(REDIS_NOTIFY_EVICTED, "evicted", keyobj, db-&gt;id); decrRefCount(keyobj); keys_freed++; // 将从机回复空间中的数据及时发送给从机 /* When the memory to free starts to be big enough, we may * start spending so much time here that is impossible to * deliver data to the slaves fast enough, so we force the * transmission here inside the loop. */ if (slaves) flushSlavesOutputBuffers(); &#125; &#125; // 未能释放空间，且此时 redis 使用的内存大小依旧超额，失败返回 if (!keys_freed) return REDIS_ERR; /* nothing to free... */ &#125; return REDIS_OK;&#125; 官方说明地址：https://redis.io/topics/lru-cache]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[可供参考的Spring集成Redis的方式]]></title>
    <url>%2F2017%2F06%2F02%2F%E5%8F%AF%E4%BE%9B%E5%8F%82%E8%80%83%E7%9A%84Spring%E9%9B%86%E6%88%90Redis%E7%9A%84%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单机版配置文件12345678910111213141516&lt;!-- 加载配置属性文件 --&gt; &lt;context:property-placeholder ignore-unresolvable="true" location="classpath:redis.properties" /&gt; &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxIdle" value="300" /&gt; &lt;!-- 最大能够保持idel状态的对象数 --&gt; &lt;property name="maxTotal" value="60000" /&gt; &lt;!-- 最大分配的对象数 --&gt; &lt;property name="testOnBorrow" value="true" /&gt; &lt;!-- 当调用borrow Object方法时，是否进行有效性检查 --&gt; &lt;/bean&gt; &lt;bean id="jedisPool" class="redis.clients.jedis.JedisPool"&gt; &lt;constructor-arg index="0" ref="jedisPoolConfig" /&gt; &lt;constructor-arg index="1" value="$&#123;redis.host&#125;" /&gt; &lt;constructor-arg index="2" value="$&#123;redis.port&#125;" type="int" /&gt; &lt;constructor-arg index="3" value="$&#123;redis.timeout&#125;"/&gt; &lt;constructor-arg index="4" value="$&#123;redis.password&#125;"/&gt; &lt;/bean&gt; Sentinel哨兵模式redis.properties内容12345678910111213141516##sentinel1的IP和端口 redis.sentinel1.host=192.168.1.55 redis.sentinel1.port=26379 ##sentinel2的IP和端口 redis.sentinel2.host=192.168.1.56 redis.sentinel2.port=26380 redis.password=abc@123$321 #最大闲置连接数 redis.maxIdle=50 #最大连接数，超过此连接时操作redis会报错 redis.maxTotal=200 redis.maxWaitTime=3000 redis.testOnBorrow=true #最小闲置连接数，spring启动的时候自动建立该数目的连接供应用程序使用，不够的时候会申请。 redis.minIdle=30 配置文件123456789101112131415161718192021&lt;context:property-placeholder ignore-unresolvable="true" location="classpath:redis.properties" /&gt; &lt;bean id="poolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxTotal" value="$&#123;redis.maxTotal&#125;" /&gt; &lt;property name="minIdle" value="$&#123;redis.minIdle&#125;" /&gt; &lt;property name="maxWaitMillis" value="$&#123;redis.maxWaitTime&#125;" /&gt; &lt;property name="maxIdle" value="$&#123;redis.maxIdle&#125;" /&gt; &lt;property name="testOnBorrow" value="$&#123;redis.testOnBorrow&#125;" /&gt; &lt;property name="testOnReturn" value="true" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;/bean&gt; &lt;bean id="jedisSentinelPool" class="redis.clients.jedis.JedisSentinelPool"&gt; &lt;constructor-arg index="0" value="mymaster" /&gt; &lt;constructor-arg index="1"&gt; &lt;set&gt; &lt;value&gt;$&#123;redis.sentinel1.host&#125;:$&#123;redis.sentinel1.port&#125;&lt;/value&gt; &lt;value&gt;$&#123;redis.sentinel2.host&#125;:$&#123;redis.sentinel2.port&#125;&lt;/value&gt; &lt;/set&gt; &lt;/constructor-arg&gt; &lt;constructor-arg index="2" ref="poolConfig" /&gt; &lt;constructor-arg index="3" value="$&#123;redis.password&#125;" /&gt; &lt;/bean&gt; Redis Cluster集群模式配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;!-- Jedis链接池配置，Jedis版本建议升级到最新 --&gt; &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxTotal" value="100" /&gt; &lt;property name="maxIdle" value="20" /&gt; &lt;property name="minIdle" value="10" /&gt; &lt;property name="blockWhenExhausted" value="true"&gt;&lt;/property&gt; &lt;property name="maxWaitMillis" value="3000" /&gt; &lt;property name="testOnBorrow" value="false" /&gt; &lt;property name="testOnReturn" value="false" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;property name="minEvictableIdleTimeMillis" value="60000" /&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="30000" /&gt; &lt;property name="numTestsPerEvictionRun" value="-1" /&gt; &lt;/bean&gt; &lt;!-- JedisCluster --&gt; &lt;bean id="jedisCluster" class="redis.clients.jedis.JedisCluster"&gt; &lt;constructor-arg index="0"&gt; &lt;set&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg index="0" value="192.168.1.111" /&gt; &lt;constructor-arg index="1" value="7111" type="int" /&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg index="0" value="192.168.1.112" /&gt; &lt;constructor-arg index="1" value="7112" type="int" /&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg index="0" value="192.168.1.113" /&gt; &lt;constructor-arg index="1" value="7113" type="int" /&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg index="0" value="192.168.1.114" /&gt; &lt;constructor-arg index="1" value="7114" type="int" /&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg index="0" value="192.168.1.115" /&gt; &lt;constructor-arg index="1" value="7115" type="int" /&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg index="0" value="192.168.1.116" /&gt; &lt;constructor-arg index="1" value="7116" type="int" /&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/constructor-arg&gt; &lt;constructor-arg index="1" value="2000" type="int"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg index="2" value="100" type="int"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg index="3" ref="jedisPoolConfig"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; Redis Sharding集群模式配置文件1234567891011121314151617181920212223242526272829&lt;!-- jedis 连接池配置--&gt; &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxActive" value="$&#123;redis.pool.maxActive&#125;" /&gt; &lt;property name="maxIdle" value="$&#123;redis.pool.maxIdle&#125;" /&gt; &lt;property name="maxWait" value="$&#123;redis.pool.maxWait&#125;" /&gt; &lt;property name="testOnBorrow" value="$&#123;redis.pool.testOnBorrow&#125;" /&gt; &lt;/bean&gt; &lt;!-- jedis 多个服务器配置--&gt; &lt;bean id="jedisShardInfo1" class="redis.clients.jedis.JedisShardInfo"&gt; &lt;constructor-arg index="0" value="$&#123;redis2.ip&#125;" /&gt; &lt;constructor-arg index="1" value="$&#123;redis.port&#125;" type="int" /&gt; &lt;property value="$&#123;redis.password&#125;" name="password"/&gt; &lt;/bean&gt; &lt;bean id="jedisShardInfo2" class="redis.clients.jedis.JedisShardInfo"&gt; &lt;constructor-arg index="0" value="$&#123;redis.ip&#125;" /&gt; &lt;constructor-arg index="1" value="$&#123;redis.port&#125;" type="int" /&gt; &lt;property value="$&#123;redis.password&#125;" name="password"/&gt; &lt;/bean&gt; &lt;bean id="shardedJedisPool" class="redis.clients.jedis.ShardedJedisPool"&gt; &lt;constructor-arg index="0" ref="jedisPoolConfig" /&gt; &lt;constructor-arg index="1"&gt; &lt;list&gt; &lt;ref bean="jedisShardInfo1" /&gt; &lt;ref bean="jedisShardInfo2"/&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;/bean&gt;]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[低成本高可用Redis集群解决方案设计]]></title>
    <url>%2F2017%2F05%2F30%2F%E4%BD%8E%E6%88%90%E6%9C%AC%E9%AB%98%E5%8F%AF%E7%94%A8Redis%E9%9B%86%E7%BE%A4%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[前言Redis高可用方案，看到较多的是Keepalived、Zookeeper方案。Keepalived是主备模式，意味着总有一台浪费着，Keepalived方案配置简单、人力成本小，在数据量少、压力小的情况下推荐使用。Zookeeper工作量成本偏高。可以利用Redis提供的特性，构建低成本高可用的Redis集群。 Redis Sentinel（哨兵）Sentinel是Redis官方为集群提供的高可用解决方案。在实际项目中可以使用sentinel去做redis自动故障转移，减少人工介入的工作量。另外sentinel也给客户端提供了监控消息的通知，这样客户端就可根据消息类型去判断服务器的状态，去做对应的适配操作。 Sentinel主要功能列表： 监控（Monitoring）：Sentinel持续检查集群中的master、slave状态，判断是否存活。 通知（Notification）：在发现某个redis实例死的情况下，Sentinel能通过API通知系统管理员或其他程序脚本。 自动故障转移（Automatic failover）：如果一个master挂掉后，sentinel立马启动故障转移，把某个slave提升为master。其他的slave重新配置指向新master，并且应用程序使用Redis服务端通知的新地址。 配置提供者（Configuration provider）：对于客户端来说sentinel通知是有效可信赖的。客户端会连接sentinel去请求当前master的地址，一旦发生故障sentinel会提供新地址给客户端。 Redis Sentinel是一个分布式系统：Sentinel（哨兵）自身被设计成和多个哨兵进程一起合作运行。有多个Sentinel（哨兵）进程合作的好处有：1.当多个Sentinel（哨兵）对一个master不再可用达成一致时执行故障检测。这会降低错误判断的概率。2.即使在不是所有的Sentinel（哨兵）都工作时哨兵也会工作，使系统健壮的抵抗故障。毕竟在故障系统里单点故障没有什么意义。Redis的Sentinel（哨兵）、Redis实例(master和slave)、和客户端是一个有特种功能的大型分布式系统。 高可用性解决方案由一个或多个Sentinel实例组成的Sentinel系统可以监视任意多个主服务器，以及所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器属下的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。 示例图： Sentinel配置Sentinel本质上只是一个运行在特殊模式下的redis服务器，通过不同配置来区分提供服务。Redis源码中包含了一个名为sentinel.conf的文件，这个文件是一个带有详细注释的Sentinel 配置。 [监控主服务器名称] [ip] [port] [多少sentinel同意才发生故障转移] sentinel monitor mymaster 127.0.0.1 6379 2 [监控主服务器名称] [master多少毫秒后不回应ping命令，就认为master是主观下线状态] sentinel down-after-milliseconds mymaster 6000 [故障转移超时时间] sentinel failover-timeout mymaster 180000 [在执行故障转移时,最多可以有多少个从服务器同时对新的主服务器进行同步] sentinel parallel-syncs mymaster 1 down-after-milliseconds解释： 当实例超过该时间没有返回PING，或者直接返回错误，那么Sentinel将这个实例标记为主观下线（简称SDOWN），只有一个Sentinel进程将实例标记为主观下线并不一定会引起实例的自动故障迁移；只有在足够数量的Sentinel 都将一个实例标记为主观下线之后，实例才会被标记为客观下线（简称ODOWN），这时自动故障迁移才会执行。只有一个Sentinel进程将实例标记为主观下线并不一定会引起实例的自动故障迁移，只有在足够数量的Sentinel都将一个实例标记为主观下线之后，实例才会被标记为客观下线，这时自动故障迁移才会执行。 parallel-syncs解释： 在发生故障转移主备切换时，这个选项指定了最多可以有多少个slave同时对新的master进行同步，这个数字越小，完成故障转移所需的时间就越长，但是如果这个数字越大，就意味着越多的slave因为replication而不可用。可以通过将这个值设为1来保证每次只有一个slave处于不能处理命令请求的状态。 启动后Sentinel会：1.以10秒一次的频率，向被监视的master发送info命令，根据回复获取master当前信息。2.以1秒一次的频率，向所有redis服务器、包含sentinel在内发送PING命令，通过回复判断服务器是否在线。3.以2秒一次的频率，通过向所有被监视的master，slave服务器发送包含当前sentinel，master信息的消息。另外建议sentinel至少起3个实例以上，并配置2个实例同意即可发生转移。 5个实例，配置3个实例同意以此类推。 故障转移消息接收的3种方式Redis服务器一旦发送故障后，sentinel通过raft算法投票选举新master。故障转移过程可以通过sentinel的API获取/订阅接收事件消息。 脚本接收当故障转移期间，可以指定一个“通知”脚本用来告知系统管理员，当前集群的情况。脚本被允许执行的最大时间为60秒，如果超时，脚本将会被终止(KILL)。 sentinel notification-script mymaster /var/redis/notify.sh 故障转移期之后，配置通知客户端的脚本。 sentinel client-reconfig-script mymaster /var/redis/notifyReconfig.sh 客户端接收Sentinel的故障转移消息通知使用的是redis发布订阅。就是说在故障转移期间所有产生的事件信息，都通过频道(channel)发布出去。比如我们加台slave服务器，sentinel监听到后会发布加slave的消息到”+slave”频道上，客户端只需要订阅”+slave”频道即可接收到对应消息。 其消息格式如下：[实例类型] [事件服务器名称] [服务器ip] [服务器端口] @[master名称] [ip] [端口] @ 通知消息格式示例： //订阅类型， *即订阅所有事件消息。-sdown //消息类型slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6381 服务间接接收这种方式在第二种基础上扩展了一层，即应用端不直接订阅sentinel。 单独做服务去干这件事情，然后应用端提供API供这个服务回调通知。这样做的好处： 减少应用端监听失败出错的可能性。 应用端由主动方变成被动方，降低耦合。 性能提高，轮询变回调。 独立成服务可扩展性更高 （1）以后换掉sentinel，我们只需要动服务即可，应用端无需更改。（2）可以在服务内多增加一层守护线程去主动拉取redis状态，这样可确保即使sentinel不生效，也能及时察觉redis状态，并通知到应用端。当然这种情况很极端，因为sentinel配的也是多节点，同时挂的几率非常小。 Redis官网sentinel配置介绍：https://redis.io/topics/sentinel]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux查看系统资源占用的总结]]></title>
    <url>%2F2017%2F05%2F26%2FLinux%E6%9F%A5%E7%9C%8B%E7%B3%BB%E7%BB%9F%E8%B5%84%E6%BA%90%E5%8D%A0%E7%94%A8%E7%9A%84%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[在系统维护和项目问题分析过程中，随时可能有需要查看 CPU和内存的使用率，并根据相应信息分析系统状况的需求和问题。我们需要知道和用到Linux系统资源查看命令。 命令：toptop命令用来显示执行中的程序进程，使用权限是所有用户。第一行表示的项目依次为当前时间、系统启动时间、当前系统登录用户数目、平均负载。第二行显示的是所有启动的进程、目前运行的、挂起(Sleeping)的和无用(Zombie)的进程。第三行显示的是目前CPU的使用情况，包括系统占用的比例、用户使用比例、闲置(Idle)比例。第四行显示物理内存的使用情况，包括总的可以使用的内存、已用内存、空闲内存、缓冲区占用的内存。第五行显示交换分区使用情况，包括总的交换分区、使用的、空闲的和用于高速缓存的大小。第六行显示的项目：PID（Process ID）：进程标示号。USER：进程所有者的用户名。PR：进程的优先级别。NI：进程的优先级别数值。VIRT：进程占用的虚拟内存值。RES：进程占用的物理内存值。SHR：进程使用的共享内存值。S：进程的状态，其中S表示休眠，R表示正在运行，Z表示僵死状态，N表示该进程优先值是负数。%CPU：该进程占用的CPU使用率。%MEM：该进程占用的物理内存和总内存的百分比。TIME＋：该进程启动后占用的总的CPU时间。Command：进程启动的启动命令名称，如果这一行显示不下，进程会有一个完整的命令行。 命令：freefree命令用来显示内存的使用情况，使用权限是所有用户。格式：free [－b－k－m] [－o] [－s delay] [－t] [－V] free -m -s5（终端会连续不断地报告内存使用情况（以MB为单位），每5秒更新一次。） Mem行：total = used + free 其中buffers和cached虽然计算在used内， 但其实为可用内存。Mem下一行：used为真实已占内存，free为真实可用内存。Swap：内存交换区的使用情况。 命令：ps auxw | head -1;ps auxw|sort -rn -k4|head -5查看内存占用前五的进程 内存的单位是KB，VSZ是虚拟内存的占用，RSS是真实的内存的占用。ps auxw：显示系统资源占用情况。head -1：表示显示第一列，即标题列。sort -r：表示反向排序，-n表示按数字排序，-k4表示列的第4个字符。 命令：pstree/pstree -p查看进程树，ps aux查看进程，如果进程太多看起来很不方便，可以使用pstree以树形方式显示正在运行的所有进程。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统数据一致性的思考（一）]]></title>
    <url>%2F2017%2F04%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[CAP理论说到分布式系统的设计，我们都或多或少的接触过CAP；CAP代表的是什么呢？ Consistency(一致性)，数据一致更新，所有数据变动都是同步的；所有的节点上的数据时刻保持同步； Availability(可用性)，好的响应性能；每个请求都能接受到一个响应，无论响应成功或失败； Partition tolerance(分区容错) ，可靠性；系统应该能持续提供服务，即使系统内部有消息丢失（分区）； CAP理论在互联网界有着广泛的知名度，知识宽泛一点的工程师都会把其作为衡量系统设计的准则。我们非常清楚地理解了CAP：任何分布式系统在可用性、一致性、分区容错性方面，不能兼得，最多只能得其二，因此，任何分布式系统的设计只是在三者中的不同取舍而已。（CAP在国内比价响，在国外的响力完全不如所想，相反还伴随着诸多的争论。）可以肯定的是，CAP并不适合再作为一个适应任何场景的定理，它的正确性更加适合基于原子读写的NoSQL场景。 高可用框架中数据一致性在某些电商的业务场景下，系统一般会有多个独立的服务组成的，比如在一个业务场景下，一个业务操作同时调用了A，B，C服务，需要满足要么同时成功，要么同时失败。A，B，C可能是不同的部门开发的，部署在不同机器上的远程服务。 对于分布式系统来说，如果不想牺牲一致性，CAP的理论告诉我们要弃用可用性，对于有些场景下是不能接受的。说到数据一致性，先介绍一下数据一致性的理论基础： 强一致性当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。当然这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。根据 CAP 理论，这种实现需要牺牲可用性。强一致性可以理解为在任意时刻，所有节点中的数据是一样的。 弱一致性系统并不保证续进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。 最终一致性弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。 在系统的实践中，为了保证系统的高可用性，互联网系统大多将强一致性需求转换成最终一致性的需求并通过系统执行幂等性的保证，保证数据的最终一致性。 BASE和方案BASEBASE是指基本可用（Basically Available）、软状态（Soft State）、最终一致性（Eventual Consistency）。BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）。ACID是传统数据库常用的设计理念，追求强一致性模型。BASE支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性。ACID和BASE代表了两种截然相反的设计哲学；在分布式系统设计的场景中，系统组件对一致性要求是不同的，因此ACID和BASE又会结合使用。 方案一【消息日志+本地事务】为了保证系统数据的最终一致性，可以使用本地事务来操作。首先需要分布式处理的任务通过消息日志的方式来异步执行。消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则或人工发起重试。人工重试更多的是应用于支付场景，通过对账系统对事后问题的处理。消息日志的方案核心是保证服务接口的幂等性。考虑到网络通讯失败、数据丢包等原因，如果接口不能保证幂等性，数据的唯一性将很难保证。其中一个经典的解决方法，来达到多次重试的幂等性。最常见的场景，如果产生一笔交易，需要在交易表中增加记录，同时还要修改用户表的金额，将主要的修改操作和更新用户表的消息放在一个本地事务来完成；为了避免重复消费用户表的消息带来的问题，达到多次重试的幂等性，增加一个更新记录表来记录已经处理过的消息。基于以上的方法，在第一阶段，通过本地的数据库的事务保障，增加事务表以及消息队列。在第二阶段，分别读出消息队列，通过判断更新记录表来检测相关的记录是否被执行，未被执行的记录会修改用户表然后增加一条操作记录到更新记录表，事务执行成功之后再删除队列。 方案二【分布式事务】目前很多的电商系统随着业务规模的扩大，将原来的一个单体应用拆分成多个不同职责的子系统。最开始的单体应用所有的功能都在一起，存储也在一起，可以在一个事务中，有关系数据库来保证一致性。但是拆分之后就不同了，不同的子系统都有自己的存储，通过接口、RPC等方式来调用不同的子系统的服务，而不是直接操作数据库。这就涉及到一个[分布式事务]的问题。对于分布式事务的解决方案，一般有2种。(1)优先使用异步消息在使用异步消息的时候消费者端要实现幂等。实现幂等的方式有2种，一种是业务逻辑保证幂等。比如接到支付成功的消息订单状态要变成支付完成，如果当前状态是支付完成，则再收到一个支付成功的消息说明消息重复了，直接作为消息成功处理。另一种方式是如果业务逻辑无法保证幂等，则要增加一个去重表或是类似的实现。对于消息生产者端在业务数据库的同实例中放一个消息库，发消息和业务操作在同一个本地事务中。发消息的时候并不立即发出，而是向消息库中插入一条消息记录，然后在事务提交的时候再异步将消息发出，发送成功则将消息库中消息删除，如果遇到消息队列服务异常或者网络异常，消息没有成功发出消息还留在库里，会有另一个服务不断的将这些消息扫出重新发送。 (2)每个业务库使用一个事务记录库有的业务不适合使用异步消息的方式，事务的各个参与方都需要同步的得到结果。采取在每个参与方的本地业务库中的同实例中放一个事务记录库。比如A同步调用B，C。A本地事务成功的时候更新本地事务记录状态，B和C同样。如果有一次A调用B失败了，有可能是B真的失败了，也有可能是调用超时，实际上B成功了。则由一个中心服务对比三方的事务记录表，做一个最终的决定。假设在三方的事务表中，有的成功，有的失败。 重试B，只到B成功，事务表里记录了各项调用参数等信息； 执行A和B的补偿操作（一种可行补偿方式就是回滚）那么会有人觉得在业务库中的同实例中存放消息库或是事务记录库，会对业务侵入，业务还需要关心这个，是否是一个合理的设计？实际上可以依靠运维手段来简化开发的侵入，可以采用的方法是通过DBA在MySQL实例上预初始化这个库，通过框架层（消息的客户端或事务RPC框架）透明的在背后操作这个库，业务开发人员只需要关心自己的业务逻辑，不需要访问这个库。总结起来，两种方式的原理是类似的，也就是将分布式事务转换成多个本地事务，然后依靠重试等方式达到最终一致性。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper系列学习：解决分布式系统中的单点故障]]></title>
    <url>%2F2017%2F04%2F02%2FZookeeper%E7%B3%BB%E5%88%97%E5%AD%A6%E4%B9%A0%EF%BC%9A%E8%A7%A3%E5%86%B3%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%8D%95%E7%82%B9%E6%95%85%E9%9A%9C%2F</url>
    <content type="text"><![CDATA[使用场景现在很多时候我们的服务需要7*24小时工作，假如一台机器挂了，我们希望能有其它机器顶替它继续工作。此类问题现在多采用master-salve模式，也就是常说的主从模式，正常情况下主机提供服务，备机负责监听主机状态，当主机异常时，可以自动切换到备机继续提供服务，这个切换过程中选出下一个主机的过程就是master选举。 传统的解决方式是采用一个备用节点，这个备用节点定期给当前主节点发送ping包，主节点收到ping包后会向备用节点发送应答ack，当备用节点收到应答，就认为主节点还活着，让它继续提供服务，否则就认为主节点挂掉了，自己将开始行使主节点职责。 当主节点挂了，这时候备用节点收不到回复了，然后他就认为主节点挂了接替他成为主节点。 但是这种方式就是有一个隐患，就是网络问题。主节点的并没有挂，只是在回复的时候网络发生故障，这样我们的备用节点同样收不到回复，就会认为主节点挂了，然后备用节点将他的Master实例启动起来，这样我们的分布式系统当中就有了两个主节点也就是—双Master，出现Master以后我们的从节点就会将它所做的事一部分汇报给了主节点，一部分汇报给了从节点，这样服务就全乱了。 使用ZooKeeperZooKeeper 能够很容易的实现集群管理的功能，如有多台 Server 组成一个服务集群，那么必须要一个“总管”知道当前集群中每台机器的服务状态，一旦有机器不能提供服务，集群中其它集群必须知道，从而做出调整重新分配服务策略。同样当增加集群的服务能力时，就会增加一台或多台 Server，同样也必须让“总管”知道。Zookeeper不仅能够维护当前的集群中机器的服务状态，而且能够选出一个“总管”，让这个总管来管理集群。 实现方式实现方式都是在ZooKeeper上创建一个 EPHEMERAL 类型的目录节点，然后每个Server在它们创建目录节点的父目录节点上调用 getChildren(String path, boolean watch) 方法并设置 watch为true，由于是 EPHEMERAL 目录节点，当创建它的Server死去，这个目录节点也随之被删除，所以Children将会变化，这时 getChildren上的Watch将会被调用，所以其它 Server就知道已经有某台Server死去了。新增 Server 也是同样的原理。和前面的一样每台Server创建一个EPHEMERAL目录节点，不同的是它还是一个SEQUENTIAL目录节点，所以它是个EPHEMERAL_SEQUENTIAL目录节点。之所以它是EPHEMERAL_SEQUENTIAL目录节点，是因为我们可以给每台Server编号，我们可以选择当前是最小编号的Server为Master，假如这个最小编号的Server死去，由于是EPHEMERAL节点，死去的Server 对应的节点也被删除，所以当前的节点列表中又出现一个最小编号的节点，我们就选择这个节点为当前Master。这样就实现了动态选择Master，避免了传统意义上单Master 容易出现单点故障的问题。 解决方案1.启动引入了Zookeeper以后我们启动了两个主节点，”主节点-A”和”主节点-B”他们启动以后，都向ZooKeeper去注册一个节点。假设”主节点-A”锁注册地节点是”master-00001”，”主节点-B”注册的节点是”master-00002”，注册完以后进行选举，编号最小的节点将在选举中获胜获得锁成为主节点，也就是我们的”主节点-A”将会获得锁成为主节点，然后”主节点-B”将被阻塞成为一个备用节点。那么，通过这种方式就完成了对两个Master进程的调度。 2.故障处理如果”主节点-A”挂了，这时候他所注册的节点将被自动删除，ZooKeeper会自动感知节点的变化，然后再次发出选举，这时候”主节点-B”将在选举中获胜，替代”主节点-A”成为主节点。 3.恢复如果主节点恢复了，他会再次向ZooKeeper注册一个节点，这时候他注册的节点将会是”master-00003”，ZooKeeper会感知节点的变化再次发动选举，这时候”主节点-B”在选举中会再次获胜继续担任”主节点”，”主节点-A”会担任备用节点。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>分布式</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper系列学习：数据模型和特点]]></title>
    <url>%2F2017%2F03%2F06%2FZookeeper%E7%B3%BB%E5%88%97%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%89%B9%E7%82%B9%2F</url>
    <content type="text"><![CDATA[ZooKeeper数据模型紧接着上一篇的概述中所写的数据模型的概述，接下来对数据模型比较详细的阐述。 ZooKeeper的数据模型，在结构上和标准文件系统的非常相似，都是采用树形层次结构，ZooKeeper树中的每个节点被称为—Znode。和文件系统的目录树一样，ZooKeeper目录树中每一个节点对应一个Znode，ZooKeeper树中的每个节点可以拥有子节点。每个Znode上可存储少量数据。用户对Znode具有增、删、改、查等操作（权限允许的情况下）。Znode具有原子性操作，每个Znode的数据将被原子性地读写，读操作会读取与Znode相关的所有数据，写操作会一次性替换所有数据。每个Znode维护着一个属性结构，它包含着版本号(dataVersion)，时间戳(ctime,mtime)等状态信息。ZooKeeper正是使用节点的这些特性来实现它的某些特定功能。每当Znode的数据改变时，他相应的版本号将会增加。每当客户端检索数据时，它将同时检索数据的版本号。并且如果一个客户端执行了某个节点的更新或删除操作，他也必须提供要被操作的数据版本号。如果所提供的数据版本号与实际不匹配，那么这个操作将会失败。 Znode是客户端访问ZooKeeper的主要实体，它包含以下几个特征：（1）Watches客户端可以在节点上设置watch(我们称之为监视器)。当节点状态发生改变时(数据的增、删、改)将会触发watch所对应的操作。当watch被触发时，ZooKeeper将会向客户端发送且仅发送一条通知，因为watch只能被触发一次。（2）数据访问ZooKeeper中的每个节点存储的数据要被原子性的操作。也就是说读操作将获取与节点相关的所有数据，写操作也将替换掉节点的所有数据。另外，每一个节点都拥有自己的ACL(访问控制列表)，这个列表规定了用户的权限，即限定了特定用户对目标节点可以执行的操作。（3）Znode节点类型ZooKeeper中的节点有两种，分别为临时节点和永久节点。节点的类型在创建时即被确定，并且不能改变。①临时节点：该节点的生命周期依赖于创建它们的会话。一旦会话(Session)结束，临时节点将被自动删除，当然可以也可以手动删除。虽然每个临时的Znode都会绑定到一个客户端会话，但他们对所有的客户端还是可见的。另外，ZooKeeper的临时节点不允许拥有子节点。②永久节点：该节点的生命周期不依赖于会话，并且只有在客户端显示执行删除操作的时候，他们才能被删除。ZooKeeper的永久节点：该节点的生命周期不依赖于会话，并且只有在客户端显示执行删除操作的时候，他们才能被删除。（4）顺序节点（唯一性的保证）当创建Znode的时候，用户可以请求在ZooKeeper的路径结尾添加一个递增的计数。这个计数对于此节点的父节点来说是唯一的，它的格式为”%10d”(10位数字，没有数值的数位用0补充，例如”0000000001”)。当计数值大于2^32-1时，计数器将溢出。org.apache.zookeeper.CreateMode中定义了四种节点类型，分别对应：PERSISTENT：永久节点EPHEMERAL：临时节点PERSISTENT_SEQUENTIAL：永久节点、序列化EPHEMERAL_SEQUENTIAL：临时节点、序列化 ZooKeeper服务中的操作在ZooKeeper中有9个基本操作:更新ZooKeeper操作是有限制的。delete或setData必须明确要更新的Znode的版本号，我们可以调用exists找到。如果版本号不匹配，更新将会失败。更新ZooKeeper操作是非阻塞式的。因此客户端如果失去了一个更新（由于另一个进程在同时更新这个Znode），他可以在不阻塞其他进程执行的情况下，选择重新尝试或进行其他操作。尽管ZooKeeper可以被看做是一个文件系统，但是处于便利，摒弃了一些文件系统地操作原语。因为文件非常的小并且使整体读写的，所以不需要打开、关闭或是寻地的操作。 每个Znode由3部分组成:1.stat：此为状态信息, 描述该Znode的版本, 权限等信息。2.data：与该Znode关联的数据。3.children：该Znode下的子节点。 Zonde总结（1）Znode中的数据可以有多个版本，在查询该Znode数据时就需要带上版本信息。如：set path version / delete path version（2）Znode可以是临时Znode，由create -e 生成的节点，一旦创建这个Znode的client与server断开连接，该Znode将被自动删除。client和server之间通过heartbeat来确认连接正常，这种状态称之为session，断开连接后session失效。（3）临时Znode不能有子Znode。（4）Znode可以自动编号，由create -s 生成的节点，例如在 create -s /app/node 已存在时，将会生成 /app/node00*001节点。（5）Znode可以被监控，该目录下某些信息的修改，例如节点数据、子节点变化等，可以主动通知监控注册的client。事实上，通过这个特性，可以完成许多重要应用，例如配置管理、信息同步、分布式锁等等。 ACL对Znode进行访问控制ZooKeeper使用ACL来对Znode进行访问控制。ACL的实现和Unix文件访问许可非常相似：它使用许可位来对一个节点的不同操作进行允许或禁止的权限控制。但是，和标准的Unix许可不同的是，Zookeeper对于用户类别的区分，不止局限于所有者(owner)、组 (group)、所有人(world)三个级别。Zookeeper中，数据节点没有“所有者”的概念。访问者利用id标识自己的身份，并获得与之相应的不同的访问权限。 ZooKeeper的节点有5种操作权限：CREATE、READ、WRITE、DELETE、ADMIN 也就是 增、删、改、查、管理权限，这5种权限简写为crwda(即：每个单词的首字符缩写)。 ACL可以控制访问ZooKeeper的节点，只能应用于特定的Znode上，而不能应用于该Znode的所有孩子节点上。它主要有如下五种权限：CREATE 允许创建Child NodesREAD 允许获取Znode的数据，以及该节点的孩子列表WRITE 可以修改Znode的数据DELETE 可以删除一个孩子节点ADMIN 可以设置权限 注：这5种权限中，delete是指对子节点的删除权限，其它4种权限指对自身节点的操作权限。 更新ZooKeeper操作是有限制的。delete或setData必须明确要更新的Znode的版本号，我们可以调用exists找到。如果版本号不匹配，更新将会失败。更新ZooKeeper操作是非阻塞式的。因此客户端如果失去了一个更新(由于另一个进程在同时更新这个Znode)，他可以在不阻塞其他进程执行的情况下，选择重新尝试或进行其他操作。尽管ZooKeeper可以被看做是一个文件系统，但是处于便利，摒弃了一些文件系统地操作原语。因为文件非常的小并且使整体读写的，所以不需要打开、关闭或是寻地的操作。 Watches（监视）Znode发生变化（Znode本身的增加，删除，修改，以及子Znode的变化）可以通过Watch机制通知到客户端。1.一次性的触发器（one-time trigger）ZooKeeper中的Watch是只能触发一次。也就是说，如果客户端在指定的Znode设置了Watch，如果该Znode数据发生变更，ZooKeeper会发送一个变更通知给客户端，同时触发设置的Watch事件。如果Znode数据又发生了变更，客户端在收到第一次通知后没有重新设置该Znode的Watch，则ZooKeeper就不会发送一个变更通知给客户端。Watch机制规定了它是一个一次性的触发器。当设置监视的数据发生改变时，该监视事件会被发送到客户端，例如，如果客户端调用了 getData(“/znode1”, true) 并且稍后 /znode1 节点上的数据发生了改变或者被删除了，客户端将会获取到 /znode1 发生变化的监视事件，而如果 /znode1 再一次发生了变化，除非客户端再次对 /znode1 设置监视，否则客户端不会收到事件通知。 2.发送给客户端（Sent to the client）ZooKeeper异步通知设置Watch的客户端。但是ZooKeeper能够保证在Znode的变更生效之后才会异步地通知客户端，然后客户端才能够看到Znode的数据变更。由于网络延迟，多个客户端可能会在不同的时间看到Znode数据的变更，但是看到变更的顺序是能够保证有序一致的。这就表明不同的客户端收到的Watch的时间可能不同，但是ZooKeeper有保证：当一个客户端在看到Watch事件之前是不会看到结点数据的变化的。 Zookeeper 客户端和服务端是通过Socket进行通信的，由于网络存在故障，所以监视事件很有可能不会成功地到达客户端，监视事件是异步发送至监视者的，Zookeeper 本身提供了保序性(ordering guarantee)：即客户端只有首先看到了监视事件后，才会感知到它所设置监视的Znode发生了变化网络延迟或者其他因素可能导致不同的客户端在不同的时刻感知某一监视事件，但是不同的客户端所看到的一切具有一致的顺序。 3.被设置Watch的数据（The data for which the watch was set）Zookeeper 维护了两条监视链表：数据监视和子节点监视(data watches and child watches)，getData()和exists()设置数据监视，getChildren()设置子节点监视。Znode可以设置两类Watch，一个是Data Watches（该Znode的数据变更导致触发Watch事件），另一个是Child Watches（该Znode的孩子节点发生变更导致触发Watch事件）。调用getData()和exists() 方法可以设置Data Watches，调用getChildren()方法可以设置Child Watches。调用setData()方法触发在该Znode的注册的Data Watches。调用create()方法创建一个Znode，将触发该Znode的Data Watches；调用create()方法创建Znode的孩子节点，则触发Znode的Child Watches。调用delete()方法删除Znode，则同时触发Data Watches和Child Watches，如果该被删除的Znode还有父节点，则父节点触发一个Child Watches。 Watch注册与处触发1.exists操作上的Watch，在被监视的Znode创建、删除或数据更新时被触发。2.getData操作上的Watch，在被监视的Znode删除或数据更新时被触发。在被创建时不能被触发，因为只有Znode一定存在，getData操作才会成功。3.getChildren操作上的Watch，在被监视的Znode的子节点创建或删除，或是这个Znode自身被删除时被触发。可以通过查看Watch事件类型来区分是Znode，还是他的子节点被删除：NodeDelete表示Znode被删除，NodeDeletedChanged表示子节点被删除。 Watch由客户端所连接的ZooKeeper服务器在本地维护，因此watch可以非常容易地设置、管理和分派。当客户端连接到一个新的服务器时，任何的会话事件都将可能触发Watch。另外，当从服务器断开连接的时候，Watch将不会被接收。但是，当一个客户端重新建立连接的时候，任何先前 注册过的watch都会被重新注册。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>分布式</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper系列学习：概述]]></title>
    <url>%2F2017%2F03%2F05%2FZookeeper%E7%B3%BB%E5%88%97%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[ZooKeeper是什么，可以用作什么官方一句话描述”ZooKeeper: A Distributed Coordination Service for Distributed Applications”。 ZooKeeper作为Hadoop项目中的一个子项目,是Hadoop集群管理的一个必不可少的模块,它主要用来解决分布式应用中经常遇到的数据管理问题，如集群管理、统一命名服务、分布式配置管理、分布式消息队列、分布式锁、分布式协调等，是分布式中一致性处理的框架的重要组件。 所谓的一致性，实际上就是围绕着“看见”来的。谁能看见？能否看见？什么时候看见？举个例子：淘宝后台卖家，在后台上架一件大促的商品，通过服务器A提交到主数据库，假设刚提交后立马就有用户去通过应用服务器B去从数据库查询该商品，就会出现一个现象，卖家已经更新成功了，然而买家却看不到；而经过一段时间后，主数据库的数据同步到了从数据库，买家就能查到了。假设卖家更新成功之后买家立马就能看到卖家的更新，则称为强一致性；如果卖家更新成功后买家不能看到卖家更新的内容，则称为弱一致性；而卖家更新成功后，买家经过一段时间最终能看到卖家的更新，则称为最终一致性。 解决一致性问题的方式常见解决问题的方式如何保证在分布式环境下数据的最终一致，这个就是ZooKeeper需要解决的问题。一些常见的解决一致性问题的方式：（1）查询重试补偿对于分布式应用中不确定的情况，先使用查询接口查询到当前状态，如果当前状态不一致则采用补偿接口对状态进行重试推进，或者回滚接口对业务做回滚。典型的场景如银行跟支付宝之间的交互。支付宝发送一个转账请求到银行，如一直未收到响应，则可以通过银行的查询接口查询该笔交易的状态，如该笔交易对方未收到，则采取补偿的模式进行推送。（2）定时任务推送有可能一次推送搞不定，于是需要2次，3次推送。当初支付宝内最初掉单率很高，全靠后续不断的定时任务推送增加成功率。（3）TCCtry-confirm-cancel。实际上是两阶段协议，第二阶段的可以实现提交操作或是逆操作。 ZooKeeper能做什么Dubbo作为业界知名的分布式SOA框架，Dubbo的主要的服务注册发现功能便是由ZooKeeper来提供的。对于一个服务框架，注册中心是其核心中的核心，虽然暂时挂掉并不会导致整个服务出问题，但是一旦挂掉，整体风险就很高。考虑一般情况，注册中心就是单台机器的时候，其实现很容易，所有机器起来都去注册服务给它，并且所有调用方都跟它保持长连接，一旦服务有变，即通过长连接来通知到调用方。但是当服务集群规模扩大时，这事情就不简单了，单机保持连接数有限，而且容易故障。作为一个稳定的服务化框架，dubbo可以选择并推荐ZooKeeper作为注册中心。其底层将ZooKeeper常用的客户端zkclient和curator封装成为ZooKeeperClient。（1）当服务提供者服务启动时，向ZooKeeper注册一个节点；（2）服务消费者则订阅其父节点的变化，诸如启动停止都能够通过节点创建删除得知，异常情况比如被调用方掉线也可以通过临时节点session 断开自动删除得知；（3）服务消费方同时也会将自己订阅的服务以节点创建的方式放到ZooKeeper；（4）于是可以得到映射关系，诸如谁提供了服务，谁订阅了谁提供的服务，基于这层关系再做监控，就能轻易得知整个系统情况。 ZooKeeper的数据模型ZooKeeper数据模型类似Linux操作系统的文件系统，也是以树的形式来存储。严格来说是一颗多叉树，每个节点上都可以存储数据，每个节点还可以拥有N个子结点，最上层是根节点以“/”来代表。在每个结点上都存储了相应的数据，数据可以是字符串、二进制数。但是默认情况下每个结点的数据大小的上限是1M，这是因为ZooKeeper主要是用来协调服务的，而不是存储数据，管理一些配置文件和应用列表之类的数据。虽然可以修改配置文件来改变数据大小的上限，但是为了服务的高效和稳定，建议结点数据不要超过默认值。在ZooKeeper中存储的创建的结点和存储的数据包含结点的创建时间、修改时间、结点id、结点中存储数据的版本、权限版本、孩子结点的个数、数据的长度等信息。每个节点的Stat结构由下列字段组成： czxid：该数据节点被创建时的事务id。 mzxid：该节点最后一次被更新时的事务id。 ctime：节点被创建时的时间。 mtime：节点最后一次被更新时的时间。 version：这个节点的数据变化的次数。 cversion：这个节点的子节点 变化次数。 aversion：这个节点的ACL变化次数。 ephemeralOwner：如果这个节点是临时节点，表示创建者的会话id。如果不是临时节点，这个值是0。 dataLength：这个节点的数据长度。 numChildren：这个节点的子节点个数。 其节点有如下有趣而又重要的特性：（1）同一时刻多台机器创建同一个节点，只有一个会争抢成功。利用这个特性可以做分布式锁。（2）临时节点的生命周期与会话一致，会话关闭则临时节点删除。这个特性经常用来做心跳，动态监控，负载等动作。（3）顺序节点保证节点名全局唯一。这个特性可以用来生成分布式环境下的全局自增长ID。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>分布式</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL的简介]]></title>
    <url>%2F2017%2F03%2F04%2FPostgreSQL%E7%9A%84%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[介绍PostgreSQL是以加州大学伯克利分校计算机系开发的POSTGRES，现在已经更名为PostgreSQL，版本4.2为基础的对象关系型数据库管理系统（ORDBMS）。POSTGRES开创的许多概念在很久以后才出现在商业数据库中。PostgreSQL支持大部分SQL标准并且提供了许多其它现代特性： 复杂查询 外键 触发器 可更新的视图 事务完整性 多版本并发控制另外，PostgreSQL可以用许多方法进行扩展，比如通过增加新的： 数据类型 函数 操作符 聚合函数 索引方法 过程语言 PostgreSQL的特点如下： PostgreSQL可在所有主要操作系统(即Linux，UNIX(AIX，BSD，HP-UX，SGI IRIX，Mac OS X，Solaris，Tru64)和Windows等)上运行。 PostgreSQL支持文本，图像，声音和视频，并包括用于C/C++，Java，Perl，Python，Ruby，Tcl和开放数据库连接(ODBC)的编程接口。 PostgreSQL支持SQL的许多功能，例如复杂SQL查询，SQL子选择，外键，触发器，视图，事务，多进程并发控制(MVCC)，流式复制(9.0)，热备(9.0))。 在PostgreSQL中，表可以设置为从“父”表继承其特征。 可以安装多个扩展以向PostgreSQL添加附加功能 PostgreSQL官方宣称的是：“The world’s most advanced open source database”。PosgreSQL还是传统B+树索引的数据库，在一些场景下，比如全插入场景，其还是会比其他一些数据库要来得差很多，比如TokuDB，MongoDB。PostgreSQL另一个痛点，我想很多人没有会意识到的，就是在在线事务（OLTP）方面的性能问题。PostgreSQL在功能方面或许是比较完整的，但是真的要进入到生产环节，看的不再是简单的功能，因为大部分用户都明白日常所使用的仅是数据库提供的20%功能。MySQL 5.7现在已经可以轻松达到50W QPS的性能，并支持通过NoSQL接口可以达到100W QPS，这是PostgreSQL为什么没有能在互联网时代站住脚跟的一个重要原因之一。在线事务对性能的要求之苛刻，是普通用户所无法感知的。 PostgreSQL最大的优势是在线分析的场景，因为其优化器对于Join的支持堪称全面，对于复杂查询有着良好的支持，从Oracle迁移到PostgreSQL的成本会比较低。基于PostgreSQL的GreenPlum也已经开源，因此PostgreSQL目前在这方便是较为领先的。 官方地址：https://www.postgresql.org/]]></content>
      <categories>
        <category>PostgreSQL</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>PostgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对于热点缓存的思考]]></title>
    <url>%2F2017%2F02%2F04%2F%E5%AF%B9%E4%BA%8E%E7%83%AD%E7%82%B9%E7%BC%93%E5%AD%98%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[热点key问题项目中通常使用 缓存+过期时间 的策略来帮助我们加速接口的访问速度，减少了后端负载，同时保证功能的更新，一般情况下这种模式已经基本满足要求了。但是有两个问题如果同时出现，可能就会对系统造成致命的危害：1.这个key是一个热点key（例如一个重要的新闻，一个热门的八卦新闻等等），所以这种key访问量可能非常大。2.缓存的构建是需要一定时间的。（可能是一个复杂计算，例如复杂的sql、多次IO、多个依赖(各种接口)等等）。 于是就会出现一个致命问题：在缓存失效的瞬间，有大量线程来构建缓存，造成后端负载加大，甚至可能会让系统崩溃。 四种解决方案我们的目标是：尽量少的线程构建缓存(甚至是一个) &amp;&amp; 数据一致性 &amp;&amp; 较少的潜在危险。 使用互斥锁的方案这种解决方案思路比较简单，就是只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据就可以。如果是单机，可以用synchronized或者lock来处理；如果是分布式环境可以用分布式锁就可以；分布式锁，可以用memcache的add，或者redis的setnx[SET if Not eXists], zookeeper的添加节点操作。 redis代码实现：12345678910111213141516String get(String key) &#123; String value = redis.get(key); if (value == null) &#123; if (redis.setnx(key_mutex, "1")) &#123; // 3 min timeout to avoid mutex holder crash redis.expire(key_mutex, 3 * 60) value = db.get(key); redis.set(key, value); redis.delete(key_mutex); &#125; else &#123; //其他线程休息50毫秒后重试 Thread.sleep(50); get(key); &#125; &#125; &#125; “提前”使用互斥锁在value内部设置1个超时值(timeout1)，timeout1比实际的timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。 memcache的代码实现：12345678910111213141516171819202122232425262728v = memcache.get(key); if (v == null) &#123; if (memcache.add(key_mutex, 3 * 60 * 1000) == true) &#123; value = db.get(key); memcache.set(key, value); memcache.delete(key_mutex); &#125; else &#123; sleep(50); retry(); &#125; &#125; else &#123; if (v.timeout &lt;= now()) &#123; if (memcache.add(key_mutex, 3 * 60 * 1000) == true) &#123; // extend the timeout for other threads v.timeout += 3 * 60 * 1000; memcache.set(key, v, KEY_TIMEOUT * 2); // load the latest value from db v = db.get(key); v.timeout = KEY_TIMEOUT; memcache.set(key, value, KEY_TIMEOUT * 2); memcache.delete(key_mutex); &#125; else &#123; sleep(50); retry(); &#125; &#125; &#125; “永远不过期”其中”永远不过期”包含两层意思：(1)从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。(2)把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期。从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。 资源保护可以使用提到了netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。 作为一个并发量较大的互联网应用，我们的目标有3个: 加快用户访问速度，提高用户体验。 降低后端负载，保证系统平稳。 保证数据“尽可能”及时更新(要不要完全一致，取决于业务，而不是技术。) 总结 解决方案 优点 缺点 简单分布式锁 思路简单;保证一致性 代码复杂度增大;存在死锁的风险;存在线程池阻塞的风险 加另外一个过期时间 保证一致性 代码复杂度增大;存在死锁的风险;存在线程池阻塞的风险 不过期 异步构建缓存，不会阻塞线程池 不保证一致性;代码复杂度增大(每个value都要维护一个timekey);占用一定的内存空间(每个value都要维护一个timekey) 资源隔离组件hystrix hystrix技术成熟，有效保证后端;hystrix监控强大 部分访问存在降级策略]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是区块链]]></title>
    <url>%2F2017%2F01%2F18%2F%E4%BB%80%E4%B9%88%E6%98%AF%E5%8C%BA%E5%9D%97%E9%93%BE%2F</url>
    <content type="text"><![CDATA[比特币区块链的工作原理 区块链区块链是比特币的底层技术，它可以理解为一种公共记账的机制，它并不是一款具体的产品。其基本思想是：通过建立一组互联网上的公共账本，由网络中所有的用户共同在账本上记账与核账，来保证信息的真实性和不可篡改性。而之所以名字叫做”区块”链，顾名思义，是因为区块链存储数据的结构是由网络上一个个”存储区块”组成一根链条，每个区块中包含了一定时间内网络中全部的信息交流数据。随着时间推移，这条链会不断增长。 从数据的角度来看：区块链是一种分布式数据库（或称为分布式共享总账，DistributedShared Ledger），这里的“分布式”不仅体现为数据的分布式存储，也体现为数据的分布式记录（即由系统参与者来集体维护）。简单的说，区块链能实现全球数据信息的分布式记录（可以由系统参与者集体记录，而非由一个中心化的机构集中记录）与分布式存储（可以存储在所有参与记录数据的节点中，而非集中存储于中心化的机构节点中）。 从效果的角度来看：区块链可以生成一套记录时间先后的、不可篡改的、可信任的数据库，这套数据库是去中心化存储且数据安全能够得到有效保证的。 交易/事务(Transactions)和区块(Blocks)交易/事务(Transactions)区块链是一个全局共享的，事务性的数据库。这个网络的每一个人都可以读取其中的记录。如果你想修改这个数据库中的东西，就必须创建一个事务，并得到其他所有人的确认。事务意味着你要做一个修改，要么被完全执行要么一点都没有执行。当你的事务被应用到这个数据库的时候，其他事务不能修改该数据库。举个例子，想象一张表，里面列出了比特币所有账号的余额。当从账户A到账户B的转账请求发生时，这个数据库的事务特性确保从账户A中减掉的金额会被加到账户B上。如果因为某种原因，往账户B增加金额无法进行，那么账户A的金额也不会发生任何变化。此外，一个事务会被发送者（事务的创建者）进行密码学签名。这项措施为数据库的修改增加了访问保护。在上面的比特币例子中，可以确保只有持有账户A密钥的人，才能从该账户向外转账。 区块(Blocks)区块链要解决的一个主要难题，在比特币中被称为“双花攻击”。当网络上出现了两笔交易，都要从一个账户中转出余额时，会发生什么？一个冲突？简单的回答是你不需要关心这个问题。这些交易会被排序并打包成“区块”，然后被所有参与的节点执行和分发。如果两笔交易相互冲突，排序靠后的交易会被拒绝并剔除出区块。这些区块按时间排成一个线性序列。这也正是“区块链”这个词的由来。区块以一个相当规律的时间间隔加入到链上。对于比特币，这个间隔大致是10分钟。而对于以太坊，这个间隔大致是17秒，以太坊对比特币做了改进，相信未来可以做到接近实时转账，就可以运用到实时性要求比较高的商业领域。作为“顺序选择机制”（通常称为“挖矿”）的一部分，一段区块链可能会时不时被回滚。但这种情况只会发生在整条链的末端。回滚涉及的区块越多，其发生的概率越小。所以你的交易可能会被回滚，甚至会被从区块链中删除。但是你等待的越久，这种情况发生的概率就越小。 区块链可以影响大行业 参考链接：[http://www.teambitcoin.com/blog/2013/5/18/bitcoin-blockchain-explained-in-infographic][https://en.wikipedia.org/wiki/Blockchain][https://datafloq.com/read/what-is-the-blockchain-and-why-is-it-so-important/2270]]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>Blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国债券市场]]></title>
    <url>%2F2017%2F01%2F10%2F%E4%B8%AD%E5%9B%BD%E5%80%BA%E5%88%B8%E5%B8%82%E5%9C%BA%2F</url>
    <content type="text"><![CDATA[中国债券市场分布 债券在投资组合中的位置 不同国债的异同点 记帐式国债的发行]]></content>
      <categories>
        <category>Finance</category>
      </categories>
      <tags>
        <tag>Finance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[债券分类,术语和债券的含义及特征]]></title>
    <url>%2F2016%2F12%2F27%2F%E5%80%BA%E5%88%B8%E5%88%86%E7%B1%BB%E5%92%8C%E6%9C%AF%E8%AF%AD%2F</url>
    <content type="text"><![CDATA[债券分类记账式债券记账式债券是指没有实物形态的票券，投资者持有的国债登记于证券账户中，投资者仅取得收据或对账单以证实其所有权的一种国债。在我国，上海证券交易所和深圳证券交易所已为证券投资者建立电脑证券账户，因此，可以利用证券交易所的系统来发行债券。我国近年来通过沪、深交易所的交易系统发行和交易的记账式国债就是这方面的实例。如果投资者进行记账式债券的买卖，就必须在证券交易所设立账户。所以，记账式国债又称无纸化国债。 凭证式国债凭证式债券的形式是一种债权人认购债券的收款凭证，而不是债券发行人制定的标准格式的债券。我国近年通过银行系统发行的凭证式国债，券面上不印制票面金额（而是根据认购者的认购额填写实际的缴款金额），是一种国家储蓄债，可记名、挂失，以“凭证式国债收款凭证”记录债权，不能上市流通，从购买之日起计息。在持有期内，持券人如果遇到特殊情况，需要提取现金，可以到购买网点提前兑取。提前兑取时，除偿还本金外，利息按实际持有天数及相应的利率档次计算，经办机构按兑付本金的0.2%收取手续费。 无记名式国债无记名式国债是一种票面上不记载债权人姓名或单位名称的债券，通常以实物券形式出现，又称实物券或国库券。实物债券是一种具有标准格式实物券面的债券。在标准格式的债券券面上，一般印有债券面额、债券利率、债券期限、债券发行人全称、还本付息方式等各种债券票面要素。有时，债券利率、债券期限等要素也可以通过公告向社会公布，而不再在债券券面上注明。 储蓄国债所谓储蓄国债，是政府面向个人投资者发行、以吸收个人储蓄资金为目的，满足长期储蓄性投资需求的不可流通记名国债品种。 企业债券企业债券为中华人民共和国国内具有法人资格的企业为筹集生产与建设资金，依照法定程序发行，约定在一定期限内还本付息的债务凭证。在中国，企业债券泛指各种所有制企业发行的债券。在西方国家，由于只有股份公司才能发行企业债券，企业债券即公司债券，它包括的范围较广，如可转换债券和资产支持证券等。 可转换公司债可转换公司债是指发行人依照法定程序发行，在一定期限内依据约定的条件可以转换成股份的公司债券。这种债券享受转换特权，在转换前是公司债形式，转换后相当于增发了股票。可转换公司债兼有债权和股权的双重性质。 金融债券金融债券是指银行及非银行金融机构依照法定程序发行并约定在一定期限内还本付息的有价证券。金融机构的资金来源很大部分靠吸收存款，但有时它们为改变资产负债结构或者用于某种特定用途，也有可能发行债券以增加资金来源。 国际债券国际债券是一种在国际上直接融通资金的金融工具，是一国政府、金融机构、工商企业或国际性组织为筹集中长期资金而在国外金融市场发行的，以外国货币为面值币种的债券。国际债券的发行者与发行地不在同一个国家，因此债券的债务人和债权人也分属不同的国家。 债券专业术语债券面值债券面值，是指债券发行时所设定的票面金额，它代表着发行人借入并承诺于未来某一特定日期（如债券到期日），偿付给债券持有人的金额。当然，债券面值和投资者购买国债而借给债券发行人的总金额是不同的。实际上，这是投资债券的本金而不是债券面值。目前，我国发行的债券，一般是每张面额为100元，10 000元的本金就可以买10张债券（这种情况出现只适用于平价发行，溢价发行和折价发行则另作别论。三种发行价格之间的区别将在下一章专门讨论）。这里的”每张面额100元”，就可以理解为债券的面值。在进行债券交易时，通过统计某种债券交易的数量，可以清楚地表明债券的交易金额。在债券的票面价值中，首先要规定票面价值的币种，即以何种货币作为债券价值的计量标准。确定币种主要考虑债券的发行对象。一般来说，在国内发行的债券通常以本国本位货币作为面值的计量单位；在国际金融市场筹资，则通常以债券发行地所在国家或地区的货币或以国际上通用的货币为计量标准。此外，确定币种还应考虑债券发行者本身对币种的需要。币种确定后，还要规定债券的票面金额。票面金额的大小不同，可以适应不同的投资对象，同时也会产生不同的发行成本。票面金额定得较小，有利于小额投资者购买，持有者分布面广，但债券本身的印刷及发行工作量大，费用可能较高；票面金额定得较大，有利于少数大额投资者认购，且印刷费用等也会相应减少，但却使小额投资者无法参与。因此，债券票面金额的确定，也要根据债券的发行对象、市场资金供给情况及债券发行费用等因素综合考虑。 净价交易净价交易，是指债券现券买卖时，以不含应计利息的价格报价并成交的交易方式，即债券持有期已计利息不计入报价和成交价格中。在进行债券现券交易清算时，买入方除按净价计算的成交价款向卖方支付外，还要向卖方支付应计利息，在债券结算交割单中债券交易净价和应计利息分别列示。目前债券净价交易采取一步到位的办法，即交易系统直接实行净价报价，同时显示债券成交价格和应计利息额，并以两项之和为债券买卖价格；结算系统直接实行净价结算，以债券成交价格与应计利息额之和为债券结算交割价格。净价=全价-应计利息。 全价目前的银行间债券市场和交易所债券市场都实行净价交易。在净价交易下，现券买卖交易时，以不含应计利息的价格（净价）报价和成交，而在结算时，再采用全价价格，也就是买方除按净价支付成交价款外，还要另向卖方支付应计利息，净价和利息这两项在交割单中分别列示，以便于国债交易的税务处理。全价、净价和应计利息三者关系如下： 全价=净价+应计利息，亦即：结算价格=成交价格+应计利息。 债券期限债券的期限即在债券发行时就确定的债券还本的年限，债券的发行人到期必须偿还本金，债券持有人到期收回本金的权利得到法律的保护。债券按期限的长短可分为长期债券 . 中期债券和短期债券。长期债券期限在 10 年以上，短期债券期限一般在 1 年以内，中期债券的期限则介于二者之间。债券的期限越长，则债券持有者资金周转越慢，在银行利率上升时有可能使投资收益受到影响。债券的期限越长，债券的投资风险也越高，因此要求有较高的收益作为补偿，而收益率高的债券价格也高。所以，为了获取与所遭受的风险相对称的收益，债券的持有人当然对期限长的债券要求较高的收益率，因而长期债券价格一般要高于短期债券的价格。 剩余期限剩余期限是指债券距离最终还本付息还有多长时间，一般以年为计算单位，其计算公式如下：剩余期限=（债券最终到期日-交易日）÷365 票面利率债券的票面利率即债券券面上所载明的利率，在债券到期以前的整个时期都按此利率计算和支付债息。在银行存款利息率不变的前提下，债券的票面利率越高，则债券持有人所获得的债息就越多，所以债券价格也就越高。反之，则越低。 应计天数起息日或上一理论付息日至结算日的实际天数。 应计利息应计利息是指自上一利息支付日至买卖结算日产生的利息收入，具体而言，零息债券是指发行起息日至交割日所含利息金额；附息债券是指本付息期起息日至交割日所含利息金额；贴现债券没有票面利率，其应计利息额设为零。应计利息的计算公式如下（以每百元债券所含利息额列示）： 应计利息额=票面利率÷365×已计息天数×100 到期收益率到期收益率（YTM[Yield to Maturity]）是使债券上得到的所有回报的现值与债券当前价格相等的收益率。它反映了投资者如果以既定的价格投资某个债券，那么按照复利的方式，得到未来各个时期的货币收入的收益率是多少。 持有期收益率持有期收益率是指从购入到卖出这段特有期限里所能得到的收益率。持有期收益率和到期收益率的差别在于将来值的不同。 修正持久期修正持久期是衡量价格对收益率变化的敏感度的指标。在市场利率水平发生一定幅度波动时，修正持久期越大的债券，价格波动越大（按百分比计）。 凸性是对债券价格利率敏感性的二阶估计，是对债券久期利率敏感性的测量。在价格-收益率出现大幅度变动时，它们的波动幅度呈非线性关系。由持久期作出的预测将有所偏离。凸性就是对这个偏离的修正。无论收益率是上升还是下降，凸性所引起的修正都是正的。因此如果修正持久期相同，凸性越大越好。 债券有四个方面的含义发行人是借入资金的经济主体；投资者是出借资金的经济主体；发行人需要在一定时期还本付息；反映了发行者和投资者之间的债权债务关系，而且是这一关系的法律凭证。 基本性质债券属于有价证券一方面，债券反映和代表一定的价值。债券本身有一定的面值，通常它是债券投资者投入资金的量化表现。同时，持有债券可按期取得利息，利息也是债券投资者收益的价值表现。另一方面，债券与其代表的权利联系在一起，拥有债券也就拥有了债券所代表的权利，转让债券也就将债券代表的权利一并转移。 债券是一种虚拟资本债券尽管债券有面值，代表了一定的财产价值，但它也只是一种虚拟资本，而非真实资本。因为债券的本质是证明债权债务关系的证书，在债权债务关系建立时所投入的资金已被债务人占用，因此，债券是实际运用的真实资本的证书。债券的流动并不意味着它所代表的实际资本也同样流动，且债券是独立于实际资本之外的。 债券是债权的表现债券代表债券投资者的权利，这种权利不是直接支配财产，也不以资产所有权表现，而是一种债权。拥有债券的人是债权人，债权人不同于财产所有人。以公司为例，在某种意义上，财产所有人可以视作公司的内部构成分子，而债权人是与公司相对立的。债权人除了按期取得本息外，对债务人不能做其他任何干预。]]></content>
      <categories>
        <category>Finance</category>
      </categories>
      <tags>
        <tag>Finance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8新特性简述]]></title>
    <url>%2F2016%2F10%2F12%2FJava8%E6%96%B0%E7%89%B9%E6%80%A7%E7%AE%80%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[Java8已经公布了比较长的一段时间，在项目中应用的比较多，接下来对Java8在项目中常应用到的一些特性做比较简要的概述。 Optional到目前为止，空指针异常是导致Java应用程序失败的最常见原因。以前，为了解决空指针异常，Google公司著名的Guava项目引入了Optional类，Guava通过使用检查空值的方式来防止代码污染，它鼓励程序员写更干净的代码。受到Google Guava的启发，Optional类已经成为Java 8类库的一部分。Optional实际上是个容器：它可以保存类型T的值，或者仅仅保存null。代码样例：12345678910111213141516171819202122232425262728293031323334353637public static void main(String args[]) &#123; //创建Optional实例，也可以通过方法返回值得到。 Optional&lt;String&gt; name = Optional.of("Optional string value"); //创建没有值的Optional实例，例如值为'null' Optional empty = Optional.ofNullable(null); //isPresent方法用来检查Optional实例是否有值。 if (name.isPresent()) &#123; //调用get()返回Optional值。 System.out.println(name.get()); &#125; try &#123; //在Optional实例上调用get()抛出NoSuchElementException。 System.out.println(empty.get()); &#125; catch (NoSuchElementException ex) &#123; System.out.println(ex.getMessage()); &#125; //如果Optional值不为空，lambda表达式会处理并在其上执行操作。 name.ifPresent((value) -&gt; &#123; System.out.println("The length of the value is: " + value.length()); &#125;); //如果有值orElse方法会返回Optional实例，否则返回传入的错误信息。 System.out.println(empty.orElse("empty.orElse, There is no value present!")); System.out.println(name.orElse(" name.orElse, There is some value!")); //orElseGet与orElse类似，区别在于传入的默认值。 //orElseGet接受lambda表达式生成默认值。 System.out.println(empty.orElseGet(() -&gt; "empty.orElseGet,Default Value")); System.out.println(name.orElseGet(() -&gt; "name.orElseGet,Default Value")); //filter方法检查给定的Option值是否满足某些条件。 //如果满足则返回同一个Option实例，否则返回空Optional。 Optional&lt;String&gt; longName = name.filter((value) -&gt; value.length() &gt; 26); System.out.println(longName.orElse("The name is less than 26 characters"));&#125; 1）of方法通过工厂方法创建Optional类。需要注意的是，创建对象时传入的参数不能为null。如果传入参数为null，则抛出NullPointerException 。2）ofNullable与of方法相似，唯一的区别是可以接受参数为null的情况。3）isPresent如果值存在返回true，否则返回false。4）get方法用来得到Optional实例中的值。下面我们看一个抛出NoSuchElementException。5）ifPresent方法，首先需要了解Consumer类。简答地说，Consumer类包含一个抽象方法。该抽象方法对传入的值进行处理，但没有返回值。6）orElse如果有值则将其返回，否则返回指定的其它值。7）orElseGet与orElse方法类似，区别在于得到的默认值。orElse方法将传入的字符串作为默认值，orElseGet方法可以接受Supplier接口的实现用来生成默认值。8）map方法用来对Optional实例的值执行一系列操作。通过一组实现了Function接口的lambda表达式传入操作。9）flatMap如果有值，为其执行mapping函数返回Optional类型返回值，否则返回空Optional。flatMap与map（Funtion）方法类似，区别在于flatMap中的mapper返回值必须是Optional。调用结束时，flatMap不会对结果用Optional封装。10）filter如果有值并且满足断言条件返回包含该值的Optional，否则返回空Optional。 官方文档：http://docs.oracle.com/javase/8/docs/api/java/util/Optional.html Stream添加的Stream API（java.util.stream）把真正的函数式编程风格引入到Java中。这是目前为止对Java类库最好的补充，因为Stream API可以极大提供Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。Stream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的 Iterator。原始版本的 Iterator，用户只能显式地一个一个遍历元素并对其执行某些操作；高级版本的 Stream，用户只要给出需要对其包含的元素执行什么操作，Stream 会隐式地在内部进行遍历，做出相应的数据转换。Stream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。Stream 的并行操作依赖于 Java7 中引入的 Fork/Join 框架来拆分任务和加速处理过程。当使用一个流的时候，通常包括三个基本步骤：获取一个数据源（source）→ 数据转换→执行操作获取想要的结果，每次转换原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道。 相关文档：https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/ Lambda 表达式简单的来讲，Lambda表达式是一个能够被传递的匿名函数。允许把函数作为一个方法的参数（函数作为参数传递进方法中）。Java 8 lambda表达式的语法：(params) -&gt; expression(params) -&gt; statement(params) -&gt; { statements } 使用Lambda表达式进行事件处理可以用lambda表达式写出更好的事件监听代码，如下所示：12345678910111213// Java 8之前：JButton show = new JButton("Show");show.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; System.out.println("Event handling without lambda expression is boring"); &#125;&#125;);// Java 8方式：show.addActionListener((e) -&gt; &#123; System.out.println("Light, Camera, Action !! Lambda expressions Rocks");&#125;); 使用Lambda表达式对列表进行迭代针对集合类，最常见的操作就是进行迭代，并将业务逻辑应用于各个元素，例如处理订单、交易和事件的列表。由于Java是命令式语言，Java 8之前的所有循环代码都是顺序的，即可以对其元素进行并行化处理。如果你想做并行过滤，就需要自己写代码，这并不是那么容易。通过引入lambda表达式和默认方法，将做什么和怎么做的问题分开了，这意味着Java集合现在知道怎样做迭代，并可以在API层面对集合元素进行并行处理。可以看到列表现在有了一个 forEach()方法，它可以迭代所有对象，并将你的lambda代码应用在其中：123456789101112// Java 8之前：List features = Arrays.asList("Lambdas", "Default Method", "Stream API", "Date and Time API");for (String feature : features) &#123; System.out.println(feature);&#125;// Java 8之后：List features = Arrays.asList("Lambdas", "Default Method", "Stream API", "Date and Time API");features.forEach(n -&gt; System.out.println(n)); // 使用Java 8的方法引用更方便，方法引用由::双冒号操作符标示，features.forEach(System.out::println); 列表循环的最后一个例子展示了如何在Java 8中使用方法引用（method reference）。 使用Lambda表达式和函数式接口PredicateJava 8也添加了一个包，叫做 java.util.function。它包含了很多类，用来支持Java的函数式编程。其中一个便是Predicate，使用 java.util.function.Predicate 函数式接口以及lambda表达式，可以向API方法添加逻辑，用更少的代码支持更多的动态行为。Predicate接口非常适用于做过滤：12345678910111213141516171819202122232425262728293031323334public static void main(args[])&#123; List languages = Arrays.asList("Java", "Scala", "C++", "Haskell", "Lisp"); System.out.println("Languages which starts with J :"); filter(languages, (str)-&gt;str.startsWith("J")); System.out.println("Languages which ends with a "); filter(languages, (str)-&gt;str.endsWith("a")); System.out.println("Print all languages :"); filter(languages, (str)-&gt;true); System.out.println("Print no language : "); filter(languages, (str)-&gt;false); System.out.println("Print language whose length greater than 4:"); filter(languages, (str)-&gt;str.length() &gt; 4);&#125;// Java 8之前：public static void filter(List names, Predicate condition) &#123; for(String name: names) &#123; if(condition.test(name)) &#123; System.out.println(name + " "); &#125; &#125;&#125;// 更好的办法public static void filter(List names, Predicate condition) &#123; names.stream().filter((name) -&gt; (condition.test(name))).forEach((name) -&gt; &#123; System.out.println(name + " "); &#125;);&#125; 使用Lambda表达式的Map和Reducemap将集合类（例如列表）元素进行转换的。还有一个 reduce()函数可以将所有值合并成一个。Map和Reduce操作是函数式编程的核心操作，因为其功能，reduce又被称为折叠操作。另外，reduce 并不是一个新的操作，你有可能已经在使用它。SQL中类似 sum()、avg()或者 count()的聚集函数，实际上就是reduce操作，因为它们接收多个值并返回一个值。流API定义的 reduceh() 函数可以接受lambda表达式，并对所有值进行合并。IntStream这样的类有类似 average()、count()、sum()的内建方法来做reduce 操作，也有mapToLong()、mapToDouble()方法来做转换。1234567891011121314// 为每个订单加上12%的税// 老方法：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);double total = 0;for (Integer cost : costBeforeTax) &#123; double price = cost + .12*cost; total = total + price;&#125;System.out.println("Total : " + total); // 新方法：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);double bill = costBeforeTax.stream().map((cost) -&gt; cost + .12*cost).reduce((sum, cost) -&gt; sum + cost).get();System.out.println("Total : " + bill); 过滤创建一个String列表过滤在大规模集合上的一个常用操作，而现在使用lambda表达式和流API过滤大规模数据集合是惊人的简单。流提供了一个 filter() 方法，接受一个 Predicate 对象，即可以传入一个lambda表达式作为过滤逻辑。下面的例子是用lambda表达式过滤Java集合：123// 创建一个字符串列表，每个字符串长度大于2List&lt;String&gt; filtered = strList.stream().filter(x -&gt; x.length()&gt; 2).collect(Collectors.toList());System.out.printf("Original List : %s, filtered list : %s %n", strList, filtered);]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[死磕并发--并发程序设计模式（五）]]></title>
    <url>%2F2016%2F09%2F24%2F%E6%AD%BB%E7%A3%95%E5%B9%B6%E5%8F%91-%E5%B9%B6%E5%8F%91%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[生产者-消费者模式生产者-消费者模式是一个经典的多线程设计模式，它为多线程之间的协作提供了良好的解决方案。在生产者-消费者模式中，通过两类线程，即若干个生产者线程和若干个消费者线程。生产者线程负责提交用户请求，消费者线程则负责处理生产者提交的任务。生产者和消费者之间通过共享内存缓冲区进行通讯。 生产者-消费者模式架构图 生产者-消费者模式中的内存缓存区的主要功能是数据在多线程间共享，此外，通过缓冲区可以缓解生产者和消费者性能差。 生产者-消费者模式的核心组件是共享内存缓存区，它作为生产者和消费者间的通信桥梁，避免了生产者和消费者的直接通信，从而将生产者和消费者进行解耦。生产者不需要知道消费者的存在，消费者也不知道生产者的存在。同时，由于内存缓冲区的存在，允许生产者和消费者在执行速度上存在时间差，无论是生产者在某一个局部时间内速度高于消费者，或是消费者在局部时间内高于生产者，都可以通过内存缓冲区得到缓解，确保系统正常运行。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[死磕并发--并发程序设计模式（四）]]></title>
    <url>%2F2016%2F09%2F23%2F%E6%AD%BB%E7%A3%95%E5%B9%B6%E5%8F%91-%E5%B9%B6%E5%8F%91%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[不变模式当多线程对同一个对象进行读写操作时，为了保证对象数据的一致性和正确性，有必要对对象进行同步。而同步操作对系统性能有相当的损耗。为了尽可能的去除这些同步操作，并提高并行程序性能，可以使用一种不可改变的对象，依靠对象的不变形，可以确保其在同步操作的多线程环境中依然保持内部状态的一致性和正确性。 不变模式天生就是多线程有好的，它的核心思想是，一个对象一旦被创建，则它的内部状态永远不会发生改变。所以，没有一个线程可以修改其内部状态和数据，同时其内部的状态绝不会发生改变。基于这些特性，对不变对象的多线程操作不需要进行同步控制。 同时需要注意，不变模式和只读属性是有一定的区别的。不变模式比只读属性具有更强的一致性和不变性。对只读属性的对象而言，对象本身不能被其他线程修改，但是对象自身状态却可能自行修改。 一个对象的存活时间（对象的创建时间和当前时间的时间差）是只读的，因为任何一个第三方线程都不能修改这个属性，但是这是一个可变的属性，因为随着时间推移，存活时间时刻发生变化。而不变模式要求，无论出于什么原因，对象自建以后，其内部的状态和数据保持绝对的稳定。 不变模式的主要的使用的场景满足以下两个条件： 当对象创建后，其内部状态和数据不再发生任何变化。 对象需要被共享、被多线程频繁访问。 样例代码123456789101112131415161718192021222324//确保无子类public final class ProductPoJo &#123; //私有属性，不被其他对象获取 private final Integer id; private final String name; private final double price; //创建对象时，必须指定数据，创建之后，无法进行修改 public ProductPoJo(Integer id, String name, double price) &#123; super(); this.id = id; this.name = name; this.price = price; &#125; public Integer getId() &#123; return id; &#125; public String getName() &#123; return name; &#125; public double getPrice() &#123; return price; &#125;&#125; 不变模式中的实现中，final关键字起到了重要关键作用。对Class的final定义保证了不变类没有子类，确保所有的getter行为不会被修改。对属性的final定义确保所有的数据只能在对象的被构造时赋值1次，之后，就永远不再发生改变。 不变模式通过回避问题而不是解决问题的态度来处理多线程并发访问。不变对象是不需要进行同步操作的。由于并发同步会对性能产生不良的影响，因此，在需求允许的情况下，不变模式可以提高系统的并发性能和并发量。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[死磕并发--并发程序设计模式（三）]]></title>
    <url>%2F2016%2F09%2F23%2F%E6%AD%BB%E7%A3%95%E5%B9%B6%E5%8F%91-%E5%B9%B6%E5%8F%91%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Guarded Suspension模式设想一个场景，服务器可能在短时间内承受大量的客户端的请求，客户端的请求数量已经超过了服务器本身的即时处理能力，而服务端又不能丢失任何一个客户请求。此时最佳的方案莫过于就是让客户端的请求进行排队，有服务端一个接一个的处理，这样即可以保证客户端所有的请求均不丢失，同时也避免服务器由于同时处理太多的请求而崩溃。Guarded Suspension解释为保护暂停，核心的思想是仅当服务端进程准备好时，才会提供服务。 Guarded Suspension的理解和实现Guarded Suspension模式的结构Request对象封装了客户端的请求。RequestQueue表示客户端的请求队列，由ClientThread和ServerThread共同维护。其中，ClientThread负责不断的发送请求，并将请求对象放入请求队列中。ServerThread根据自身状态，在有能力的处理请求时，从RequestQueue中提取请求对象加以处理。工作流程图如下： Guarded Suspension模式可以确保系统仅有在有能力处理某个任务时，才会处理该任务。当系统没有能力处理任务时，它会暂存任务信息等待系统空闲。 Guarded Suspension模式的实现RequestPoJo类1234567891011121314151617public class RequestPoJo &#123; private String name; public RequestPoJo(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; @Override public String toString() &#123; return "RequestPoJo [name=" + name + "]"; &#125;&#125; RequestQueue类1234567891011121314151617181920212223public class RequestQueue &#123; private LinkedList&lt;RequestPoJo&gt; queue = new LinkedList&lt;&gt;(); public synchronized RequestPoJo getRequest()&#123; //等到新的Request加入 while(queue.size() == 0)&#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; return (RequestPoJo) queue.remove(); &#125; public synchronized void addRequest(RequestPoJo request)&#123; //添加Request queue.add(request); notifyAll(); &#125;&#125; ClientThread类1234567891011121314151617181920212223public class ClientThread extends Thread &#123; private RequestQueue requestQueue; public ClientThread(RequestQueue requestQueue, String name) &#123; super(name); this.requestQueue = requestQueue; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; RequestPoJo request = new RequestPoJo("Request ID"+i+"Thread_name:"+Thread.currentThread().getName()); requestQueue.addRequest(request); try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+" request end."); &#125; &#125;&#125; ServerThread类1234567891011121314151617181920212223public class ServerThread extends Thread &#123; private RequestQueue requestQueue; public ServerThread(RequestQueue requestQueue, String name) &#123; super(name); this.requestQueue = requestQueue; &#125; @Override public void run() &#123; while(true)&#123; RequestPoJo request = requestQueue.getRequest(); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+" handles,"+request); &#125; &#125;&#125; Guarded Suspension模式可以在一定程度上环节系统的压力，它可以将系统的负载在时间轴上均匀的分配，有效的降低系统的瞬时负载，对提高系统的抗压力和稳定性有一定的帮助。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[死磕并发--并发程序设计模式（二）]]></title>
    <url>%2F2016%2F09%2F22%2F%E6%AD%BB%E7%A3%95%E5%B9%B6%E5%8F%91-%E5%B9%B6%E5%8F%91%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Master-Worker模式Master-Worker模式是常用的并发模式之一。中心就是，系统中有两类进程协调工作，Master进程和Worker进程，Master负责接收和分配任务，Worker负责处理子任务，当各个子任务处理完毕后，将结果返回给Master进程，Master进行归纳和汇总，得到系统的最终结果。处理过程如下： Master-Worker模式的好处能够将一个大任务分解成若干的小任务执行，并行执行，提高系统的吞吐量。任务一旦提交，Master进程就会分配任务并立即返回，并不会等待系统全部处理完成后再返回，其处理过程是异步的。因此，Client不会出现等待的现象。 Master-Worker理解和实现Master-Worker模式结构Master-Worker模式结构相对比较简单。Master进程为主要进程，维护一个Worker进程队列、子任务队列和子结果集。Worker进程队列中的Worker进程，不停的从任务队列中提取要处理的子任务，并将子任务的结果写入结果集中。 Master-Worker模式简单的代码实现Master的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Master &#123; //任务队列 protected Queue&lt;Object&gt; workQueue = new ConcurrentLinkedQueue&lt;&gt;(); //Work进程队列 protected Map&lt;String, Thread&gt; threadMap = new ConcurrentHashMap&lt;&gt;(); //子任务处理结果集 protected Map&lt;String, Object&gt; resultMap = new ConcurrentHashMap&lt;&gt;(); //是否所有的子任务都结束了 public boolean isComplete()&#123; for (Map.Entry&lt;String, Thread&gt; entry : threadMap.entrySet()) &#123; if (entry.getValue().getState() != Thread.State.TERMINATED) &#123; return false; &#125; &#125; return true; &#125; //构造Master， public Master(Worker worker, int counrWorker)&#123; worker.setWorkQueue(workQueue); worker.setResultMap(resultMap); for (int i = 0; i &lt; counrWorker; i++) &#123; threadMap.put(Integer.toString(i), new Thread(worker,Integer.toString(i))); &#125; &#125; //提交一个任务 public void submit(Object task)&#123; workQueue.add(task); &#125; //运行Woker进程，进行处理 public void execute()&#123; for (Map.Entry&lt;String, Thread&gt; entry : threadMap.entrySet()) &#123; entry.getValue().start(); &#125; &#125; //获取结果集 public Map&lt;String, Object&gt; getResultMap() &#123; return resultMap; &#125; &#125; Worker的实现以及子类1234567891011121314151617181920212223242526272829303132333435public class Worker implements Runnable&#123; //任务队列，获取子任务 protected Queue&lt;Object&gt; workQueue; //子任务处理的结果集 protected Map&lt;String, Object&gt; resultMap; public void setWorkQueue(Queue&lt;Object&gt; workQueue) &#123; this.workQueue = workQueue; &#125; public void setResultMap(Map&lt;String, Object&gt; resultMap) &#123; this.resultMap = resultMap; &#125; //子任务处理逻辑，可以用于子类的实现具体逻辑 public Object handle(Object input)&#123; return input; &#125; @Override public void run() &#123; while(true)&#123; //获取子任务 Object input = workQueue.poll(); if (input == null ) &#123; break; &#125; //处理子任务 Object res = handle(input); //结果写入结果集 resultMap.put(Integer.toString(input.hashCode()), res); &#125; &#125;&#125; 123456789public class PlusWorker extends Worker &#123; @Override public Object handle(Object input) &#123; Integer d = (Integer)input; return d*d*d; &#125;&#125; Main方法1234567891011121314151617181920212223242526272829303132333435//计算1--100的立方的和public class MainTest &#123; public static void main(String[] args) &#123; Master master = new Master(new PlusWorker(), 5); for (int i = 0; i &lt; 101; i++) &#123; master.submit(i); &#125; master.execute(); int res = 0; Map&lt;String, Object&gt; resultMap = master.getResultMap(); while (resultMap.size() &gt;0 || !master.isComplete()) &#123; Set&lt;String&gt; keys = resultMap.keySet(); String key = null; for (String k:keys) &#123; key = k; break; &#125; Integer i=null; if (key != null) &#123; i = (Integer) resultMap.get(key); &#125; if (i != null) &#123; res+=i; &#125; if (key != null) &#123; resultMap.remove(key); &#125; &#125; System.out.println("final res="+res); &#125;&#125; Master-Worker模式是一种将任务串行化的方案，被分解的子任务在系统中可以并行的处理。同时，如果需要，Master进程不需要等待所有的子任务都完成计算，就可以根据已有的部分结果集计算最终结果。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[死磕并发--并发程序设计模式（一）]]></title>
    <url>%2F2016%2F09%2F20%2F%E6%AD%BB%E7%A3%95%E5%B9%B6%E5%8F%91-%E5%B9%B6%E5%8F%91%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Future模式对于Future模式有点像期货市场的“期货”，是“对未来的一种凭证”；例如：我在期货交易中心买了期货，交钱之后，会拿到一个期货的凭证，这个凭证告诉我等XXXX年某个时候可以拿这个凭证来拿对方的物品，而现在我是没有办法拿到物品的，需要等到协定的时间来取。对于程序代码来讲，实现了Future模式的客户端在程序处理任务还没有返回结果时，而是去调用了其他业务逻辑的，充分利用等待时间。在完成了对其他业务的处理后，最后再使用返回比较慢的程序数据，在整个调用过程中，就不存在了无所谓的等待，充分利用所有的时间片段，从而提高整个系统的响应速度。 模式流程图基本的模式流程图 Future模式Java实现1.Main函数调用：ApplicationTest主要是client发起请求，并返回数据。12345678910111213public class ApplicationTest &#123; public static void main(String[] args) throws InterruptedException &#123; ClientMain client = new ClientMain(); // 这里会立即返回，因为获取的是FutureData，而非RealData Data data = client.request("name"); System.out.println("请求完毕！"); // 这里可以用一个sleep代替对其他业务逻辑的处理 // 在处理这些业务逻辑过程中，RealData也正在创建，从而充分了利用等待时间 Thread.sleep(2000); // 使用真实数据 System.out.println("数据=" + data.getResult()); &#125;&#125; 2.ClientMain实现：ClientMain主要实现了FutureData，开启构造RealData的线程，接收请求后很快的返回FutureData。12345678910111213141516public class ClientMain &#123; public Data request(final String string) &#123; final FutureData futureData = new FutureData(); // 开启一个新的线程来构造真实数据 new Thread(new Runnable() &#123; @Override public void run() &#123; // RealData的构建很慢，所以放在单独的线程中运行 RealData realData = new RealData(string); futureData.setRealData(realData); &#125; &#125;).start(); return futureData; // 先直接返回FutureData &#125;&#125; 3.Data的实现：Data是一个接口。123public interface Data &#123; public String getResult() throws InterruptedException;&#125; 4.FutureData的实现：FutureData实现了一个快速返回的RealData的包装。当使用FutureData的getResult()方法时，程序会阻塞，等待RealData被注入到程序中，才使用RealData的getResult()方法。123456789101112131415161718192021222324252627282930//FutureData是Future模式的关键，它实际上是真实数据RealData的代理，封装了获取RealData的等待过程public class FutureData implements Data &#123; // FutureData是RealData的封装 RealData realData = null; // 是否已经准备好 boolean isReady = false; public synchronized void setRealData(RealData realData) &#123; if (isReady)&#123; return; &#125; this.realData = realData; isReady = true; notifyAll(); // RealData已经被注入到FutureData中了，通知getResult()方法 &#125; @Override public synchronized String getResult() throws InterruptedException &#123; while (!isReady) &#123; try &#123; wait(); &#125; catch (Exception e) &#123; &#125; &#125; return realData.getResult(); &#125;&#125; 5.RealData实现：RealData是最终需要使用的数据模型，构造速度比较慢。12345678910111213141516171819202122232425public class RealData implements Data &#123; protected String data; public RealData(String data) &#123; //RealData的构建过程可能会很慢，需要用户等很长的时间 System.out.println("RealData data:"+data); StringBuffer sb = new StringBuffer(); for(int i=0;i&lt;20;i++)&#123; try &#123; sb.append("++"+data); Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; this.data = sb.toString(); &#125; @Override public String getResult() throws InterruptedException &#123; return data; &#125;&#125; JDK内置的实现在JDK自带的实现中，有关实现Future模式的核心结构如图: FutureTask是最为重要的模块，实现了RunnableFuture接口，而RunnableFuture继承Runnable和Future，实现了Runnable的接口，作为单独的线程运行。在run()的方法中维护了Callable，并维护该对象返回的对象。当FutureTask.get()方法时，将返回Callable接口的返回对象。 Future模式的核心是在于：去除了主函数的等待时间，并使得原本需要等待的时间段可以用于处理其他业务逻辑，从而充分的利用计算机资源。 FutureTask使用场景未完待续……]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有关BlockingQueue和门徒的说说（一）]]></title>
    <url>%2F2016%2F09%2F18%2F%E6%9C%89%E5%85%B3BlockingQueue%E5%92%8C%E5%AD%90%E7%B1%BB%E7%9A%84%E8%AF%B4%E8%AF%B4%2F</url>
    <content type="text"><![CDATA[关注BlockingQueue的由来JDK中提供了一套Executors框架，可以有效的帮助开发人员进行线程的控制。在项目中应用Executors这个类实现代码的时候，看到newFixedThreadPool(),newSingleThreadExecutor(),newCachedThreadPool()等的实现中利用了BlockingQueue的实现类来过工作队列。BlockingQueue是一个接口,主要的实现类有ArrayBlockingQueue, LinkedBlockingQueue, PriorityBlockingQueue, SynchronousQueue。Java API中的实现类： 在java.util.concurrent包中所有Queue的UML结构图： BlockingQueue的门徒主要探究ArrayBlockingQueue, LinkedBlockingQueue, PriorityBlockingQueue, SynchronousQueue这4个实现类[基于Java8]。 ArrayBlockingQueueArrayBlockingQueue是一个线程安全的、基于数组、有界的（初始化的时候必须要指定队列长度，且指定长度之后不允许进行修改）、阻塞的、FIFO队列。向已满的队列中存放元素导致操作阻塞，试图从空队列中提取元素导致类似阻塞。基于ReentrantLock 来实现线程安全，所以提供了ReentrantLock所能支持的公平性选择。源码：1234567891011 /** Main lock guarding all access */ final ReentrantLock lock;....... public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); &#125; 添加数据ArrayBlockingQueue有不同的几个数据添加方法:add、offer、put方法。add方法：123456public boolean add(E e) &#123; if (offer(e)) return true; else throw new IllegalStateException("Queue full");&#125; offer方法：123456789101112131415public boolean offer(E e) &#123; checkNotNull(e);// 不允许元素为空 final ReentrantLock lock = this.lock; lock.lock();// 加锁，保证调用offer方法的时候只有1个线程 try &#123; if (count == items.length)// 如果队列已满 return false;// 直接返回false，添加失败 else &#123; enqueue(e);// 数组没满的话调用enqueue方法 return true;// 返回true，添加成功 &#125; &#125; finally &#123; lock.unlock(); // 释放锁，让其他线程可以调用offer方法 &#125;&#125; 1234567891011121314/** * Inserts element at current put position, advances, and signals. * Call only when holding lock. */private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; items[putIndex] = x;// 放数据索引+1，当索引满了变成0 if (++putIndex == items.length) putIndex = 0; count++;// 元素个数+1 notEmpty.signal();// 使用条件对象notEmpty通知&#125; put方法：123456789101112public void put(E e) throws InterruptedException &#123; checkNotNull(e);// 不允许元素为空 final ReentrantLock lock = this.lock; lock.lockInterruptibly();// 加锁，保证调用put方法的时候只有1个线程 try &#123; while (count == items.length)// 如果队列满了，阻塞当前线程，并加入到条件对象notFull的等待队列里 notFull.await();// 线程阻塞并被挂起，同时释放锁 enqueue(e); // 调用enqueue方法 &#125; finally &#123; lock.unlock();// 释放锁，让其他线程可以调用put方法 &#125;&#125; ArrayBlockingQueue的添加数据方法有add,put,offer这3个方法，总结： add方法内部调用offer方法，如果队列满了，抛出IllegalStateException异常，否则返回true; offer方法如果队列满了，返回false，否则返回true; add方法和offer方法不会阻塞线程，put方法如果队列满了会阻塞线程，直到有线程消费了队列里的数据才有可能被唤醒;这3个方法内部都会使用可重入锁保证原子性。 删除数据ArrayBlockingQueue有不同的几个数据删除方法:poll、take、remove方法。poll方法：123456789public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock();// 加锁，保证调用poll方法的时候只有1个线程 try &#123; return (count == 0) ? null : dequeue();// 如果队列里没元素了，返回null，否则调用dequeue方法 &#125; finally &#123; lock.unlock();// 释放锁，让其他线程可以调用poll方法 &#125;&#125; 12345678910111213141516171819/** * Extracts element at current take position, advances, and signals. * Call only when holding lock. */private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings("unchecked") E x = (E) items[takeIndex];// 得到取索引位置上的元素 items[takeIndex] = null;// 对应取索引上的数据清空 if (++takeIndex == items.length)// 取数据索引+1，当索引满了变成0 takeIndex = 0; count--;// 元素个数-1 if (itrs != null) itrs.elementDequeued(); notFull.signal();// 使用条件对象notFull通知 return x;// 返回元素&#125; take方法：1234567891011public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly();// 加锁，保证调用take方法的时候只有1个线程 try &#123; while (count == 0)// 如果队列空，阻塞当前线程，并加入到条件对象notEmpty的等待队列里 notEmpty.await();// 线程阻塞并被挂起，同时释放锁 return dequeue();// 调用dequeue方法 &#125; finally &#123; lock.unlock();// 释放锁，让其他线程可以调用take方法 &#125;&#125; remove方法：1234567891011121314151617181920212223public boolean remove(Object o) &#123; if (o == null) return false; final Object[] items = this.items; final ReentrantLock lock = this.lock; lock.lock();// 加锁，保证调用remove方法的时候只有1个线程 try &#123; if (count &gt; 0) &#123; final int putIndex = this.putIndex; int i = takeIndex; do &#123; // 遍历元素 if (o.equals(items[i])) &#123;// 两个对象相等的话 removeAt(i);// 调用removeAt方法 return true;// 删除成功，返回true &#125; if (++i == items.length)// 元素都被删除，索引记为0 i = 0; &#125; while (i != putIndex);// 元素都被删除 &#125; return false; &#125; finally &#123; lock.unlock();// 释放锁，让其他线程可以调用remove方法 &#125;&#125; ArrayBlockingQueue的删除数据方法有poll,take,remove这3个方法，总结： poll方法对于队列为空的情况，返回null，否则返回队列头部元素; remove方法取的元素是基于对象的下标值，删除成功返回true，否则返回false; poll方法和remove方法不会阻塞线程; take方法对于队列为空的情况，会阻塞并挂起当前线程，直到有数据加入到队列中;这3个方法内部都会调用notFull.signal方法通知正在等待队列满情况下的阻塞线程。 LinkedBlockingQueueLinkedBlockingQueue是一个基于单向链表的、范围任意的（其实是有界的）、FIFO阻塞队列。访问与移除操作是在队头进行，添加操作是在队尾进行，并分别使用不同的锁进行保护，只有在可能涉及多个节点的操作才同时对两个锁进行加锁。队列是否为空、是否已满仍然是通过元素数量的计数器（count）进行判断的，由于可以同时在队头、队尾并发地进行访问、添加操作，所以这个计数器必须是线程安全的，这里使用了一个原子类 AtomicInteger，这就决定了它的容量范围是： 1 – Integer.MAX_VALUE。源码：12345678public LinkedBlockingQueue() &#123; this(Integer.MAX_VALUE);&#125;public LinkedBlockingQueue(int capacity) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; last = head = new Node&lt;E&gt;(null);&#125; 由于同时使用了两把锁，在需要同时使用两把锁时，加锁顺序与释放顺序是非常重要的：必须以固定的顺序进行加锁，再以与加锁顺序的相反的顺序释放锁。12345/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock(); 添加数据LinkedBlockingQueue有不同的几个数据添加方法：offer、put方法。offer方法：1234567891011121314151617181920212223public boolean offer(E e) &#123; if (e == null) throw new NullPointerException();// 不允许空元素 final AtomicInteger count = this.count; if (count.get() == capacity) return false;// 如果容量满了，返回false int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e);// 容量没满，以新元素构造节点 final ReentrantLock putLock = this.putLock; putLock.lock();// 放锁加锁，保证调用offer方法的时候只有1个线程 try &#123; if (count.get() &lt; capacity) &#123;// 再次判断容量是否已满，因为可能拿锁在进行消费数据，没满的话继续执行 enqueue(node);// 节点添加到链表尾部 c = count.getAndIncrement();// 元素个数+1 if (c + 1 &lt; capacity)// 如果容量还没满 notFull.signal();// 在放锁的条件对象notFull上唤醒正在等待的线程，表示可以再次往队列里面加数据了，队列还没满 &#125; &#125; finally &#123; putLock.unlock();// 释放放锁，让其他线程可以调用offer方法 &#125; if (c == 0) // 由于存在放锁和拿锁，这里可能拿锁一直在消费数据，count会变化 signalNotEmpty();// 在拿锁的条件对象notEmpty上唤醒正在等待的1个线程，表示队列里还有1条数据，可以进行消费 return c &gt;= 0;&#125; put方法：12345678910111213141516171819202122232425262728293031public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException();// 不允许空元素 // Note: convention in all put/take/etc is to preset local var // holding count negative to indicate failure unless set. int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e);// 以新元素构造节点 final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly();// 放锁加锁，保证调用put方法的时候只有1个线程 try &#123; /* * Note that count is used in wait guard even though it is * not protected by lock. This works because count can * only decrease at this point (all other puts are shut * out by lock), and we (or some other waiting put) are * signalled if it ever changes from capacity. Similarly * for all other uses of count in other wait guards. */ while (count.get() == capacity) &#123;// 如果容量满了 notFull.await();// 阻塞并挂起当前线程 &#125; enqueue(node); // 节点添加到链表尾部 c = count.getAndIncrement(); // 元素个数+1 if (c + 1 &lt; capacity)// 如果容量还没满 notFull.signal();// 在放锁的条件对象notFull上唤醒正在等待的线程，表示可以再次往队列里面加数据了，队列还没满 &#125; finally &#123; putLock.unlock(); // 释放放锁，让其他线程可以调用put方法 &#125; if (c == 0) signalNotEmpty(); // 在拿锁的条件对象notEmpty上唤醒正在等待的1个线程，表示队列里还有1条数据，可以进行消费&#125; LinkedBlockingQueue的添加数据方法put,offer跟ArrayBlockingQueue一样，不同的是它们的底层实现不一样。ArrayBlockingQueue中放入数据阻塞的时候，需要消费数据才能唤醒。而LinkedBlockingQueue中放入数据阻塞的时候，因为它内部有2个锁，可以并行执行放入数据和消费数据，不仅在消费数据的时候进行唤醒插入阻塞的线程，同时在插入的时候如果容量还没满，也会唤醒插入阻塞的线程。 删除数据LinkedBlockingQueue有不同的几个数据删除方法:poll、take、remove方法。poll方法：12345678910111213141516171819202122 public E poll() &#123; final AtomicInteger count = this.count; if (count.get() == 0)// 如果元素个数为0 return null;// 返回null E x = null; int c = -1; final ReentrantLock takeLock = this.takeLock; takeLock.lock();// 拿锁加锁，保证调用poll方法的时候只有1个线程 try &#123; if (count.get() &gt; 0) &#123; // 判断队列里是否还有数据 x = dequeue();// 删除头结点 c = count.getAndDecrement(); // 元素个数-1 if (c &gt; 1) notEmpty.signal();// 在拿锁的条件对象notEmpty上唤醒正在等待的线程，表示队列里还有数据，可以再次消费 &#125; &#125; finally &#123; takeLock.unlock();// 释放拿锁，让其他线程可以调用poll方法 &#125; if (c == capacity)// 由于存在放锁和拿锁，这里可能放锁一直在添加数据，count会变化。这里的if条件表示如果队列中还可以再插入数据 signalNotFull();// 在放锁的条件对象notFull上唤醒正在等待的1个线程 return x;&#125; take方法：123456789101112131415161718192021public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly();// 拿锁加锁，保证调用take方法的时候只有1个线程 try &#123; while (count.get() == 0) &#123;// 如果队列里已经没有元素了 notEmpty.await(); // 阻塞并挂起当前线程 &#125; x = dequeue();// 删除头结点 c = count.getAndDecrement();// 元素个数-1 if (c &gt; 1)// 如果队列里还有元素 notEmpty.signal();// 在拿锁的条件对象notEmpty上唤醒正在等待的线程，表示队列里还有数据，可以再次消费 &#125; finally &#123; takeLock.unlock();// 释放拿锁，让其他线程可以调用take方法 &#125; if (c == capacity)// 由于存在放锁和拿锁，这里可能放锁一直在添加数据，count会变化 signalNotFull();// 在放锁的条件对象notFull上唤醒正在等待的1个线程，表示队列里还能再次添加数据 return x;&#125; remove方法：1234567891011121314151617public boolean remove(Object o) &#123; if (o == null) return false; fullyLock();// remove操作要移动的位置不固定，2个锁都需要加锁 try &#123; for (Node&lt;E&gt; trail = head, p = trail.next;// 从链表头结点开始遍历 p != null; trail = p, p = p.next) &#123; if (o.equals(p.item)) &#123;// 判断是否找到对象 unlink(p, trail);// 修改节点的链接信息，同时调用notFull的signal方法 return true; &#125; &#125; return false; &#125; finally &#123; fullyUnlock();// 2个锁解锁 &#125;&#125; 1234void fullyLock() &#123; putLock.lock(); takeLock.lock();&#125; LinkedBlockingQueue的take方法对于没数据的情况下会阻塞，poll方法删除链表头结点，remove方法删除指定的对象。需要注意的是remove方法由于要删除的数据的位置不确定，需要2个锁同时加锁。 PriorityBlockingQueuePriorityBlockingQueue能使队列保持FIFO，可以在元素取完时,一直处于等待状态,PriorityBlockingQueue中用object[]来存储队列，队列中的元素需实现Comparable接口，队列通过这个接口的compare方法确定对象的priority。 添加数据PriorityBlockingQueue有不同的几个数据添加方法:add、offer、put方法。add方法：123public boolean add(E e) &#123; return offer(e);&#125; offer方法：12345678910111213141516171819202122public boolean offer(E e) &#123; if (e == null) throw new NullPointerException();// 不允许空元素，空元素抛出异常 final ReentrantLock lock = this.lock; lock.lock();// 拿锁加锁，保证调用offer方法的时候只有1个线程 int n, cap; Object[] array; while ((n = size) &gt;= (cap = (array = queue).length)) tryGrow(array, cap); try &#123; Comparator&lt;? super E&gt; cmp = comparator; if (cmp == null) siftUpComparable(n, e, array);// 插入元素，向上调整 else siftUpUsingComparator(n, e, array, cmp); size = n + 1; notEmpty.signal();// 在拿锁的条件对象notEmpty上唤醒正在等待的线程 &#125; finally &#123; lock.unlock();// 释放放锁 &#125; return true;&#125; 123456789101112private static &lt;T&gt; void siftUpComparable(int k, T x, Object[] array) &#123; Comparable&lt;? super T&gt; key = (Comparable&lt;? super T&gt;) x; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; Object e = array[parent]; if (key.compareTo((T) e) &gt;= 0) // 当待插入元素比当前位置的父元素大的时候，代表待插入元素可以插入到当前位置。 break; array[k] = e; k = parent; &#125; array[k] = key;&#125; 123456789101112private static &lt;T&gt; void siftUpUsingComparator(int k, T x, Object[] array, Comparator&lt;? super T&gt; cmp) &#123; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; Object e = array[parent]; if (cmp.compare(x, (T) e) &gt;= 0) break; array[k] = e; k = parent; &#125; array[k] = x;&#125; PriorityBlockingQueue添加新元素的时候不是将全部的元素进行顺序排序，而是从某个指定的位置开始将新元素与新添加的作比较，一直比较到队列头，这样可以保证PriorityBlockingQueue队列头一定是优先级最高的。 put方法：123public void put(E e) &#123; offer(e); // never need to block&#125; 删除数据LinkedBlockingQueue有不同的几个数据删除方法:poll、take、remove方法。poll方法：123456789public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; take方法：123456789101112public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); E result; try &#123; while ( (result = dequeue()) == null) notEmpty.await(); &#125; finally &#123; lock.unlock(); &#125; return result;&#125; remove方法：12345678910111213public boolean remove(Object o) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; int i = indexOf(o); if (i == -1) return false; removeAt(i); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; SynchronousQueueSynchronousQueue不像ArrayBlockingQueue或LinkedBlockingQueue，其内部并没有数据缓存空间，你不能调用peek()方法来看队列中是否有数据元素，因为数据元素只有当你试着取走的时候才可能存在，不取走而只想偷窥一下是不行的，当然遍历这个队列的操作也是不允许的。数据是在配对的生产者和消费者线程之间直接传递的，并不会将数据缓冲数据到队列中。可以这样来理解：生产者和消费者互相等待对方，握手，然后一起离开。每个插入操作必须等待另一个线程的对应移除操作 ，反之亦然。SynchronousQueue的一个使用场景是在Executors.newCachedThreadPool()线程池里。12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 这个线程池根据需要（新任务到来时）创建新的线程，如果有空闲线程则会重复使用，线程空闲了60秒后会被回收。 剖析此队列设计的理念类似于”单工模式”，对于每个put/offer操作，必须等待一个take/poll操作,类似于”火把传递”:一个火把传递地他人,需要2个人”触手可及”才行. 因为这种策略,最终导致队列中并没有一个真正的元素；这是一种pipleline思路的基于queue的”操作传递”。 void put(E o):向队列提交一个元素,阻塞直到其他线程take或者poll此元素； boolean offer(E o):向队列中提交一个元素,如果此时有其他线程正在被take阻塞(即其他线程已准备接收)或者”碰巧”有poll操作,那么将返回true,否则返回false； E take():获取并删除一个元素,阻塞直到有其他线程offer/put； boolean poll():获取并删除一个元素,如果此时有其他线程正在被put阻塞(即其他线程提交元素正等待被接收)或者”碰巧”有offer操作,那么将返回true,否则返回false； E peek():总会返回null,硬编码。 SynchronousQueue经常用来,一端或者双端严格遵守”单工”(单工作者)模式的场景,队列的两个操作端分别是productor和consumer。常用于一个productor多个consumer的场景。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排查Java应用CPU使用率过高]]></title>
    <url>%2F2016%2F09%2F13%2F%E6%8E%92%E6%9F%A5Java%E5%BA%94%E7%94%A8CPU%E4%BD%BF%E7%94%A8%E7%8E%87%E8%BF%87%E9%AB%98%2F</url>
    <content type="text"><![CDATA[CPU使用率过高作为工程师我们会碰到Java应用某台机器cpu比较高的情况，在允许的情况下重启后基本上都会恢复正常，但是治标不治本，过上一段时间后还会出现CPU过高的问题。一般的正常情况下：应用使用CPU在 ：30%–40%异常情况下：CPU利用率在：80%—100%一般Java应用CPU过高基本上有以下原因：1.程序计算比较密集（计算密集型应用）；2.程序死循环；3.程序逻请求堵塞；有的极端情况CPU甚至会飙到200%以上。 不过有时候还是具体问题具体分析，懂得如何查找和分析问题的原因和步骤对于问题的解决有这重要意义。 定位和解决碰到这样的问题该怎么定位和解决这类问题？ 基本的步骤（1）通过top命令找到可疑进程PID，找出消耗资源最高的线程 ；（2）通过ps aux | grep PID命令，可以进一步确定是tomcat进程出现了问题；（3）通过ps -mp pid -o THREAD,tid,time 显示线程列表；（4）通过printf “%x\n” tid 将需要的线程ID转换为16进制格式；（5）通过jstack 命令打印线程的堆栈信息； jstack pid |grep tid -A 30 或者 jstack pid |grep tid -A 60 jstack主要用来查看某个Java进程内的线程堆栈信息，jstack可以定位到线程堆栈，根据堆栈信息我们可以定位到具体代码，它在JVM性能调优中使用得非常多。 语法格式：123jstack [option] pidjstack [option] executable corejstack [option] [server-id@]remote-hostname-or-ip]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux查找命令小记]]></title>
    <url>%2F2016%2F09%2F09%2FLinux%E6%9F%A5%E6%89%BE%E5%91%BD%E4%BB%A4%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[小记在Linux系统中查找文件，定位相关的路径是攻城狮们经常遇到的，Linux就向是一个相当大的仓库，需要及时的准确的找到自己想要的路径和文件，那就需要比较好的搜索工具；搜索工具好不好关系到定位问题的精准和效率。今天在DEV环境需要查找自己很久之前部署的Redis，文件路径由于时间比较久远已经忘记了，怎么精确的快速找到自己部署的应用。经历了一段小的寻找路程，虽然耗时不是那么多的时间，记录下来以便自己和看这篇文章的同学参考。 查找Redis部署路径(1)首先我要确保我用的这台服务器上确实有Redis在运行着；查看如下图命令和操作：1234[root@vm-test01 /]# ps -ef|grep redisroot 5705 1 0 2016 ? 05:32:56 ./redis-server *:6379 root 30763 29277 0 16:52 pts/3 00:00:00 grep redis[root@vm-test01 /]# (2)使用find命令查看如下图命令和操作：12[root@vm-test01 /]# find / -name redis-server/home/redis/redis-server Linux查找命令可以使用下面的一些命令来搜索：which 查看可执行文件的位置whereis 查看文件的位置locate 配合数据库查看文件位置find 实际搜寻硬盘查询文件名称 Linux查找命令详解1.which语法: which 可执行文件名称 12[root@vm-test01 /]# which passwd/usr/bin/passwd which是通过 PATH环境变量到该路径内查找可执行文件，所以基本的功能是寻找可执行文件. 2.whereis语法: whereis [-bmsu] 文件或者目录名称参数说明：-b: 只找二进制文件-m: 只找在说明文件manual路径下的文件-s: 只找source源文件-u: 没有说明文档的文件 将和passwd文件相关的文件都查找出来12[root@vm-test01 /]# whereis passwdpasswd: /usr/bin/passwd /etc/passwd /usr/share/man/man1/passwd.1.gz /usr/share/man/man5/passwd.5.gz 只将二进制文件查找出来12[root@vm-test01 /]# whereis -b passwdpasswd: /usr/bin/passwd /etc/passwd 和find相比，whereis查找的速度非常快，这是因为linux系统会将 系统内的所有文件都记录在一个数据库文件中，当使用whereis和locate时，会从数据库中查找数据，而不是像find命令那样，通 过遍历硬盘来查找，效率自然会很高。但是该数据库文件并不是实时更新，默认情况下时一星期更新一次，因此，我们在用whereis和locate查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。 3.locate语法: locate 文件或者目录名称 12345678910111213[root@vm-test01 /]# locate redis/home/quartz/webapps/quartz-service/WEB-INF/classes/spring/applicationContext-redis.xml/home/redis/dump.rdb/home/redis/redis-benchmark/home/redis/redis-cli/home/redis/redis-server/home/redis/redis.conf/home/redis/redis.pid/home/redis/redis1.conf/home/redis/redis_init_script/home/redis/temp-12938.rdb/home/redis/temp-3575.rdb··············· 4.find语法: find 路径 参数参数说明：时间查找参数：-atime n :将n24小时内存取过的的文件列出来-ctime n :将n24小时内改变、新增的文件或者目录列出来-mtime n :将n*24小时内修改过的文件或者目录列出来-newer file :把比file还要新的文件列出来 名称查找参数：-gid n :寻找群组ID为n的文件-group name :寻找群组名称为name的文件-uid n :寻找拥有者ID为n的文件-user name :寻找用户者名称为name的文件-name file :寻找文件名为file的文件（可以使用通配符） 12[root@vm-test01 /]# find / -name redis-server/home/redis/redis-server find命令所查找的目录路径，是在硬盘上遍历查找，因此非常消耗硬盘的资源，而且效率也非常低。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让MySQL支持中文排序的实现方法]]></title>
    <url>%2F2016%2F09%2F07%2F%E8%AE%A9MySQL%E6%94%AF%E6%8C%81%E4%B8%AD%E6%96%87%E6%8E%92%E5%BA%8F%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[让MySQL支持中文排序如果在mysql中使用字符集为utf8，想要对中文字段用order by chinese_field 排序，那么出来的顺序并不是按照拼音排序的，不是我们想要的结果。 实现方法（1）方案一对于包含中文的字段加上”binary”属性，使之作为二进制比较，例如将”name char(10)”改成”name char(10)binary”。如果使用源码编译MySQL，可以编译MySQL时使用 –with–charset=gbk 参数，这样MySQL就会直接支持中文查找和排序。也可以用 extra-charsets=gb2312,gbk 来加入多个字符集。 （2）方案二可以在查询语句的order by部分使用 CONVERT 函数对中文字段使用gbk编码排序： SELECT * FROM table ORDER BY CONVERT(chinese_field USING gbk ); 当然这需要你安装mysql时安装了gbk字符集，不然会报错：#1115 - Unknown character set: ‘gbk’]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例模式]]></title>
    <url>%2F2016%2F09%2F04%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式单例模式是项目中的设计模式最普遍使用的模式之一。它是一种对象创建的模式，用于产生一个对象的具体实例，可以确保系统中一个类只产生一个实例。有2大好处：（1）对于频繁使用的对象，可以省略创建对象所花费的时间，对于那些重量级的对象而言，是一笔非常客观的系统开销；（2）由于new的操作次数减少，因而对系统内存的使用频率也会降低，这将会减轻GC的压力，缩短GC停顿的时间；对于系统的关键组件和被频繁使用的对象，使用单例可以有效的改善系统性能。 单例类的角色： 角色 作用 单例者 提供单例工厂，返回单例 使用者 获取并使用单例类 单例的实现：单例模式的核心是通过一个接口返回唯一的一个对象实例。一个简单的实现如下：123456789101112public class Singleton&#123; private Singleton()&#123; System.out.println("Singleton is created.."); &#125; private static Singleton instance = new Singleton(); public static Singleton getInstance() &#123; return instance; &#125;&#125; 首先单例类必须有一个private访问级别的构造函数，只有这样，才能保证单例不会被系统中其他代码内被实例化，这一点是相当重要的；其次instance成员变量和getInstance()方法必须是static的。它唯一不足的地方是无法对instance做延迟加载。假如单例的创建过程很慢，而由于instance成员变量是static定义的，因此在JVM加载单例类的时候，单例对象会被创建，如果此时，这个单例类在系统中扮演其他角色，那么在任何使用这个单例类的地方都会初始化这个单例变量，而不管是否被用到。 为了解决这个问题，并以此来提高系统在相关函数调用时的反应速度，就需要加入延迟加载机制。123456789101112131415public class LazySingleton&#123; private LazySingleton()&#123; System.out.println("LazySingleton is created.."); &#125; private static LazySingleton instance = null; public static synchronized LazySingleton getInstance() &#123; if (null == instance)&#123; instance = new LazySingleton(); &#125; return instance; &#125;&#125; 使用上例中的单例实现，虽然实现了延迟加载的功能，但是和第一种方法相比，它引入了同步关键字，以此在多线程环境中，它的耗时会远远大于第一种的单例的实现。 为了使用延迟加载而引入同步关键字反而降低了系统性能，是不是有点得不偿失？为了解决这个问题，对其进行改造：1234567891011121314public class StaticSingleton&#123; private StaticSingleton()&#123; System.out.println("StaticSingleton is created.."); &#125; private static class SingletonHolder &#123; private static StaticSingleton instance = new StaticSingleton(); &#125; public static StaticSingleton getInstance() &#123; return SingletonHolder.instance; &#125;&#125; 在这个实现中，单例模式使用内部类来维护单例的实例，当StaticSingleton被加载时，其内部类不会被初始化，故此可以确保StaticSingleton类被加载到JVM时，不会初始化单例类，而当getInstance()方法被调用时，才会加载SingletonHolder，从而初始化instance，同时，实例的创建是在类加载的时候完成的，故天生对多线程是友好的，getInstance()也不需要加同步关键字。这种方式兼顾以上两种实现的优点。 注意： 使用内部类的方式实现单例，既可以做到延迟加载，也不必使用同步关键字，是一种比较完善的实现。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
        <tag>设计优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁的基本原理]]></title>
    <url>%2F2016%2F09%2F03%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[基本概念目前几乎很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。为了保证数据的最终一致性，需要很多的技术方案来支持，比如分布式事务、分布式锁等。分布式锁，是控制分布式系统之间同步访问共享资源的一种方式。在分布式系统中，常常需要协调他们的动作。如果不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要互斥来防止彼此干扰来保证一致性。 举个例子1.假设有一个进程A，每小时准点给用户发送一条短信”Hello world”，为了高可用，就必须在多台机器上面部署多个进程，避免宕机的情况。2.假设部署在两台机器，那么问题来了，用户每个小时就会收到两条”Hello world”，信息就重复了3.我们希望只发送一条”Hello world”，那么就可以引入分布式锁的概念了。4.进程A和进程B发送短信前先去注册一个锁，假设进程A抢到了锁，进程B就等待结果，如果发送成功了，那么就B就放弃此次任务，等待下一个小时。5.问题的核心就在于怎么注册锁，检查锁的存在和注册锁是一个原子性操作，类似MySQL的主键，存在则不能insert，就说是你不能把我的锁覆盖了，你得等着。6.我们有多种方式可以实现分布式锁，最简单的就是以每小时准点这个时间作为主键，到MySQL写入一条数据，利用数据库来维持一致性。 针对分布式锁的实现，目前比较常用的有以下几种方案：1.基于数据库实现分布式锁2.基于缓存（redis，memcached）实现分布式锁3.基于Zookeeper实现分布式锁]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作中一段SQL的优化]]></title>
    <url>%2F2016%2F05%2F07%2F%E5%B7%A5%E4%BD%9C%E4%B8%AD%E4%B8%80%E6%AE%B5SQL%E7%9A%84%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[优化一段逻辑SQL在工作中，在看到一段SQL语句很长，执行的效率比较慢，每个表都有好几百万数据，单查一个表差不多3秒左右，两个表union跑了将近20秒，需要进行优化。 原先的SQL语句：12345678910111213141516171819202122232425SELECT a.bondUniCode,a.bondShortName,SUM(a.ofrPrice)AS ofrPrice,SUM(a.ofrVol)AS ofrVol,SUM(a.bidPrice)AS bidPrice,SUM(a.bidVol)AS bidVol,a.sendTime FROM ( SELECT t.bond_uni_code AS bondUniCode, t.bond_short_name AS bondShortName, 0 AS ofrPrice, 0 AS ofrVol, CASE WHEN t.bond_price IS NULL THEN 0 ELSE MAX(t.bond_price) END AS bidPrice, 0 AS bidVol, CASE WHEN t.send_time IS NULL THEN '' ELSE DATE_FORMAT(t.send_time, '%Y-%m-%d') END AS sendTime FROM dmdb.t_bond_quote t WHERE t.`status` = 1 AND t.side = 1 AND t.bond_uni_code 0 AND t.price_unit = 2 AND DATE_FORMAT(t.send_time, '%Y-%m-%d')= '2016-04-10' GROUP BY t.bond_uni_code UNION SELECT t.bond_uni_code AS bondUniCode, t.bond_short_name AS bondShortName, CASE WHEN t.bond_price IS NULL THEN 0 ELSE MIN(t.bond_price) END AS ofrPrice, 0 AS ofrVol, 0 AS bidPrice, 0 AS bidVol, CASE WHEN t.send_time IS NULL THEN '' ELSE DATE_FORMAT(t.send_time, '%Y-%m-%d') END AS sendTime FROM dmdb.t_bond_quote t WHERE t.`status` = 1 AND t.side = 2 AND t.bond_uni_code 0 AND t.price_unit = 2 AND DATE_FORMAT(t.send_time, '%Y-%m-%d')= '2016-04-10'GROUP BY t.bond_uni_code ) a GROUP BY a.bondUniCode; 分析(1)观察这段SQL的逻辑主要是按照条件（查询条件相同，除了side不同外）查询最大和最小的price的值；(2)查询条件中使用了DATE_FORMAT函数；(3)使用了UNION做联合； 观察分析之后： 2段SQL是否可以写成一个SQL呢？毕竟是差不多的查询条件，或者可以在查询的结果中做min和max的筛选呢； 使用explain查看sql,在WHERE中使用DATE_FORMAT的send_time并没有使用到索引，使用该函数会使查询索引失效； 如果可以将逻辑合并一个SQL中，UNION就可以不用； 优化后的SQL123456789SELECT t.bond_uni_code AS bondUniCode,t.bond_short_name AS bondShortName,MIN(CASE WHEN t.bond_price IS NOT NULL AND t.side = 2 THEN t.bond_price WHEN t.bond_price IS NULL AND t.side = 2 THEN 0 END) AS ofrPrice,0 AS ofrVol, MAX(CASE WHEN t.bond_price IS NOT NULL AND t.side = 1 THEN t.bond_price WHEN t.bond_price IS NULL AND t.side = 1 THEN 0 END) AS bidPrice,0 AS bidVol,CASE WHEN t.send_time IS NULL THEN '' ELSE DATE_FORMAT(t.send_time, '%Y-%m-%d') END AS sendTime FROM dmdb.t_bond_quote t WHERE t.`status` = 1 AND t.bond_uni_code 0 AND t.price_unit = 2 AND t.send_time BETWEEN '2017-06-10 000000' AND '2016-04-10 235959'GROUP BY t.bond_uni_code; 优化后的SQL语句在相同的环境下执行效率提高了N倍，而且可以查询到与优化前的SQL的同样的结果。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2016%2F05%2F03%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[优秀的程序员都在使用Google]]></title>
    <url>%2F2016%2F04%2F15%2F%E4%BC%98%E7%A7%80%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%91%98%E9%83%BD%E5%9C%A8%E4%BD%BF%E7%94%A8Google%2F</url>
    <content type="text"><![CDATA[“能在书本上简单查到的东西永远不要放进你的记忆里。” 在程序员界众所周知，百度在搜索技术资料方面有天生的白痴特性，而且GitHub的博客屏蔽了百度蜘蛛的抓取，基本上身边优秀的程序员或者架构师极力推荐搜索资料的时候要使用Google，基本上搜索到的内容前三页可以覆盖你所要解决的问题的情况。 用Google可以查到GitHub上内容，接触了开源社区，Google + Stackoverflow + GitHub就再也没有解决不了的问题了，而某种意义上，开发其实主要就是解决问题的能力。]]></content>
      <categories>
        <category>Google</category>
      </categories>
      <tags>
        <tag>Google</tag>
      </tags>
  </entry>
</search>